{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"What is MNE-BIDS-Pipeline?","text":"<p>MNE-BIDS-Pipeline is a full-flegded processing pipeline for your MEG and EEG data.</p> <ul> <li>It operates on data stored according to the Brain Imaging Data Structure (BIDS).</li> <li>Under the hood, it uses MNE-Python.</li> </ul> <p>Get started Learn more</p>"},{"location":"index.html#what-the-pipeline-offers","title":"What the pipeline offers","text":"<ul> <li> Automated processing of MEG and EEG data from raw data to inverse solutions.</li> <li> Configuration via a simple text file.</li> <li> Extensive processing and analysis summary reports.</li> <li> Process just a single participant, or as many as several hundreds of participants \u2013 in parallel.</li> <li> Execution via an easy-to-use command-line utility.</li> <li> Helpful error messages in case something goes wrong.</li> <li> Data processing as a sequence of standard processing steps.</li> <li> Steps are cached to avoid unnecessary recomputation.</li> <li> Data can be \"ejected\" from the pipeline at any stage. No lock-in!</li> <li> Runs on your laptop, on a powerful server, or on a high-performance cluster via Dash.</li> </ul> <p>Get started </p>"},{"location":"changes.html","title":"What's new","text":""},{"location":"changes.html#v150-2023-11-30","title":"v1.5.0 (2023-11-30)","text":"<p>This release contains a number of very important bug fixes that address problems related to decoding, time-frequency analysis, and inverse modeling. All users are encouraged to update.</p>"},{"location":"changes.html#new-features-enhancements","title":"New features &amp; enhancements","text":"<ul> <li>Added <code>deriv_root</code> argument to CLI (#773 by @vferat)</li> <li>Added support for annotating bad segments based on head movement velocity (#757 by @larsoner)</li> <li>Added examples of T1 and FLASH BEM to website (#758 by @larsoner)</li> <li>Added support for extended SSS (eSSS) in Maxwell filtering (#762 by @larsoner)</li> <li>Output logging spacing improved (#764 by @larsoner)</li> <li>Added caching of sensor and source average steps (#765 by @larsoner)</li> <li>Improved logging of coregistration distances (#769 by @larsoner)</li> <li>Input validation has been improved by leveraging pydantic (#779 by @larsoner)</li> <li>Reduced logging when reports are created and saved (#799 by @hoechenberger)</li> <li>Added <code>\"picard-extended_infomax\"</code> ICA algorithm to perform \"extended Infomax\"-like ICA decomposition using Picard (#801 by @hoechenberger)</li> <li>Added support for using \"local\" <code>autoreject</code> to find (and repair) bad channels on a   per-epoch basis as the last preprocessing step; this can be enabled by setting <code>reject</code>   to <code>\"autoreject_local\"</code>. The behavior can further be controlled via the new setting   <code>autoreject_n_interpolate</code>. (#807 by @hoechenberger)</li> <li>Added support for \"local\" <code>autoreject</code> to remove bad epochs   before submitting the data to ICA fitting. This can be enabled by setting <code>ica_reject</code>   to <code>\"autoreject_local\"</code>. (#810, #816 by @hoechenberger)</li> <li>The new setting <code>decoding_which_epochs</code> controls which epochs (e.g., uncleaned, after ICA/SSP, cleaned) shall be used for decoding. (#819 by @hoechenber)</li> <li> <p>Website documentation tables can now be sorted (e.g., to find examples that use a specific feature) (#808 by @larsoner)</p> </li> <li> <p>The default cache directory is now <code>_cache</code> within the derivatives folder when using <code>memory_location=True</code>, set <code>memory_subdir=\"joblib\"</code> to get the behavior from v1.4 (#778 by @larsoner)</p> </li> <li>Before cleaning epochs via ICA, we used to reject any epochs execeeding the <code>ica_reject</code>   criteria. However, this may lead to the unnecessary exclusion of epochs that could have been salvaged through ICA cleaning. Now,   we only apply <code>ica_reject</code> to the epochs used for ICA fitting. After the experimental epochs have been cleaned with ICA   (<code>preprocessing/apply_ica</code> step), any remaining large-amplitude artifacts can be removed via   <code>reject</code>, which is used in the last preprocessing step, <code>preprocessing/ptp_reject</code>. (#806 by @hoechenberger)</li> <li>MVPA / decoding used to be performed on un-cleaned epochs in the past. Now, cleaned epochs will be used by default (please also see the \"Bug fixes\" section below). (#796 by @hoechenberger)</li> </ul>"},{"location":"changes.html#code-health","title":"Code health","text":"<ul> <li>Fixed doc build errors and dependency specifications (#755 by @larsoner)</li> <li>Ensure <code>memory_file_method = \"hash\"</code> is tested (#768 by @larsoner)</li> <li>Enable pre-commit.ci (#774 by @larsoner)</li> <li>Use <code>pooch</code> for web downloads (#775 by @larsoner)</li> <li>Ensure compatibility with MNE-Python 1.6 (#800 by @hoechenberger)</li> <li>Updated testing dataset for ds004229 v1.0.3 (#808 by @larsoner)</li> </ul>"},{"location":"changes.html#bug-fixes","title":"Bug fixes","text":"<ul> <li>Fixed bug where cache would not invalidate properly based on output file changes and steps could be incorrectly skipped. All steps will automatically rerun to accommodate the new, safer caching scheme (#756 by @larsoner)</li> <li>Fixed bug with parallelization across runs for Maxwell filtering (#761 by @larsoner)</li> <li>Fixed bug where head position files were not written with a proper suffix and extension (#761 by @larsoner)</li> <li>Fixed bug where default values for <code>decoding_csp_times</code> and <code>decoding_csp_freqs</code> were not set dynamically based on the config parameters (#779 by @larsoner)</li> <li>Fixed bug where the MNE logger verbosity was not respected inside parallel jobs (#813 by @larsoner)</li> <li>A number of processing steps erroneously always operated on un-cleaned epochs (<code>sensor/decoding_full_epochs</code>, <code>sensor/decoding_time_by_time</code>, <code>sensor/decoding_csp</code>); or operated on un-cleaned epochs (without PTP rejection) if no ICA or SSP was requested (<code>sensor/ime_frequency</code>, <code>sensor/make_cov</code>) The bug in <code>sensor/make_cov</code> could propagate to the source level, as the covariance matrix is used for inverse modeling. (#796 by @hoechenberger)</li> <li>Bad channels may have been submitted to MVPA (full epochs decoding, time-by-time decoding, CSP-based decoding) when not using Maxwell filtering   (i.e., usually only EEG data was affected). This has now been fixed and data from bad channels is omitted from decoding. (#817 by @hoechenberger)</li> </ul>"},{"location":"changes.html#v140-2023-07-04","title":"v1.4.0 (2023-07-04)","text":""},{"location":"changes.html#new-features-enhancements_1","title":"New features &amp; enhancements","text":"<ul> <li>Add movement compensation and cHPI filtering to the Maxwell filtering step, along with additional configuration options (#747 by @larsoner)</li> <li>Add option to specify <code>ssp_ecg_channel</code> to override the default value (#747 by @larsoner)</li> <li>Add option <code>read_raw_bids_verbose</code> to set the verbosity level when using <code>read_raw_bids</code> to suppress known warnings (#749 by @larsoner)</li> </ul>"},{"location":"changes.html#code-health_1","title":"Code health","text":"<ul> <li>Refactor code to deduplicate keyword-passing and improve internal logic (#746, #749 by @larsoner)</li> </ul>"},{"location":"changes.html#bug-fixes_1","title":"Bug fixes","text":"<ul> <li>Fix bug when <code>mf_reference_run != runs[0]</code> (#742 by @larsoner)</li> <li>Fix bug with too many JSON files found during empty-room discovery (#743 by @allermat)</li> <li>Fix bug where SSP projectors were not added to the report (#747 by @larsoner)</li> <li>Fix documentation of <code>data_type</code> configuration option (#751 by @allermat)</li> <li>Fix documentation of <code>ch_types</code> configuration option (#745 by @allermat)</li> </ul>"},{"location":"changes.html#v130-released-20230601","title":"v1.3.0 (released 2023/06/01)","text":""},{"location":"changes.html#new-features-enhancements_2","title":"New features &amp; enhancements","text":"<ul> <li>Provide a more helpful log message if the CSP decoding step is being skipped (#734 by @hoechenberger)</li> <li>Use <code>rich</code> for improved logging control and styling (#737 by @larsoner)</li> </ul>"},{"location":"changes.html#code-health_2","title":"Code health","text":"<ul> <li>Avoid using deprecated <code>openpyxl</code> API when working with Excel spreadsheets (#735 by @larsoner)</li> </ul>"},{"location":"changes.html#bug-fixes_2","title":"Bug fixes","text":"<ul> <li>Fix pandas 2.0 compatibility (#732 by @larsoner)</li> <li>Fix bug with <code>mne.sys_info</code> insertion in reports (#732 by @larsoner)</li> <li>Always generate CSP decdoing grand average analysis if CSP decoding was used on the single-subject level (#733 by @hoechenberger)</li> </ul>"},{"location":"changes.html#v120-released-20230323","title":"v1.2.0 (released 2023/03/23)","text":""},{"location":"changes.html#new-features-enhancements_3","title":"New features &amp; enhancements","text":"<ul> <li>We improved caching to reduce initialization time when large datasets are being processed. (#720 by @apmellot)</li> </ul>"},{"location":"changes.html#behavior-changes","title":"Behavior changes","text":"<ul> <li>MNE-BIDS-Pipeline now requires MNE-Python 1.2 or newer.</li> </ul>"},{"location":"changes.html#code-health_3","title":"Code health","text":"<ul> <li>Replace legacy <code>plot_psd()</code> calls with <code>compute_psd().plot()</code>   (#725 by @drammock)</li> </ul>"},{"location":"changes.html#v110-released-20220113","title":"v1.1.0 (released 2022/01/13)","text":""},{"location":"changes.html#new-features-enhancements_4","title":"New features &amp; enhancements","text":"<ul> <li>Add support for notch filtering (#702 by @hoechenberger and @larsoner)</li> </ul>"},{"location":"changes.html#v103-released-20221218","title":"v1.0.3 (released 2022/12/18)","text":""},{"location":"changes.html#behavior-changes_1","title":"Behavior changes","text":"<p>This backward-incompatible change was made before officially announcing the release, so we are bumping the patch version number rather than the major version number.</p> <ul> <li>The <code>N_JOBS</code> parameter has been renamed to   <code>n_jobs</code> for consistency   (#694 by @larsoner)</li> </ul>"},{"location":"changes.html#bug-fixes_3","title":"Bug fixes","text":"<ul> <li>The <code>stable</code> documentation deployment was fixed   (#682 by @larsoner )</li> </ul>"},{"location":"changes.html#code-health_4","title":"Code health","text":"<ul> <li>Code quality now checked by ruff   and black   (#689, #690, and #691 by @larsoner)</li> <li>Documentation building infrastructure improved by using newer mkdocs   extensions   (#693 by @hoechenberger)</li> </ul>"},{"location":"changes.html#v102-released-20221207","title":"v1.0.2 (released 2022/12/07)","text":""},{"location":"changes.html#code-health_5","title":"Code health","text":"<ul> <li>The repository README.md was improved   (#680 by @hoechenberger )</li> </ul>"},{"location":"changes.html#v101-released-20221206","title":"v1.0.1 (released 2022/12/06)","text":""},{"location":"changes.html#behavior-changes_2","title":"Behavior changes","text":"<p>These backward-incompatible changes have been made before officially announcing the release, so we are bumping the patch version number rather than the major version number.</p> <ul> <li>The <code>epochs_decim</code> setting   replaces <code>decim</code> for consistency and readability   (#502 by @larsoner )</li> <li>The <code>raw_resample_sfreq</code>   setting replaces <code>resample_sfreq</code> for consistency and readability   (#502 by @larsoner )</li> </ul>"},{"location":"changes.html#v100-released-20221201","title":"v1.0.0 (released 2022/12/01)","text":"<p>Changes were only tracked starting April 15, 2021.</p>"},{"location":"changes.html#new-features-enhancements_5","title":"New features &amp; enhancements","text":"<ul> <li>An official project governance structure has officially   been adopted.</li> <li>The peak-to-peak (PTP) amplitude rejection thresholds for epochs can now   optionally be determined automatically using   <code>autoreject</code> by setting the   <code>reject</code> parameter to <code>'autoreject_global'</code>.   (#306 by @agramfort and @hoechenberger)</li> <li>The new configuration option <code>ica_reject</code> allows to   exclude epochs from the ICA fit based on peak-to-peak (PTP) amplitude.   (#302 by @hoechenberger)</li> <li>Drastically reduces memory usage when creating epochs from datasets with   multiple runs.   (#355 by @hoechenberger)</li> <li>Add time-frequency plot to report.   (#367 by @rob-luke)</li> <li>Add possibility to exclude runs from the analysis via the new   <code>exclude_runs</code> setting.   (#370 by @crsegerie)</li> <li>Add possibility to process resting-state data via   <code>rest_epochs_duration</code> and   <code>rest_epochs_overlap</code>.   (#393 by @apmellot, @dengemann,    @agramfort, and @hoechenberger)</li> <li>We now create high-resolution scalp surfaces for visualization of the   coregistration in the reports. Existing surfaces can be force-regenerated by   setting the new <code>recreate_scalp_surface</code>   to <code>True</code>.   (#378 by @hoechenberger)</li> <li>When not applying Maxwell-filter (i.e., when   <code>use_maxwell_filter</code> is set to <code>False</code>, e.g.   when processing EEG data), we skip the initial data import that would   essentially just copy the input data to the derivatives root without doing   any processing. Now, in such situations, the Maxwell-filtering step is   skipped entirely, and we start with frequency filtering right away. This   speeds up processing by avoiding unnecessary disk I/O and can help preserve   large quantities of storage space for big datasets.   (#378 by @dengemann and @hoechenberger)</li> <li>Break periods in the continuous data can now be automatically detected and   annotated as \"bad\" segments, which will be ignored during subsequent   processing. This feature is disabled by default and can be switched on via   the <code>find_breaks</code> setting.   (#386 by @hoechenberger)</li> <li>You can now use the FreeSurfer <code>fsaverage</code> template MRI for source estimation   in cases where you don't have participant-specific MR scans available, as is   often the case in EEG studies. The behavior can be enabled using the new   configuration option <code>use_template_mri</code>.   (#387), gh(526 by @agramfort and @hoechenberger)</li> <li>You can now specify rejection parameters and the number of projection   vectors per channel type for SSP via   <code>n_proj_eog</code>, <code>n_proj_ecg</code>,   <code>ssp_reject_eog</code> and   <code>ssp_reject_ecg</code>.   (#392 by @agramfort, @dengemann,    @apmellot and @hoechenberger)</li> <li>You can now use autoreject for excluding artifacts before SSP estimation via   the <code>autoreject_global</code> option in <code>ssp_reject_eog</code>   and <code>ssp_reject_ecg</code>.   (#396 by @agramfort, @dengemann,    @apmellot and @hoechenberger)</li> <li>You can now specify a custom   <code>eeg_template_montage</code> from any   <code>mne.channels.montage.DigMontage</code> object.   (#407 by @dengemann, @hoechenberger and    @agramfort)</li> <li>Certain BIDS file system operations are now being cached, which should   significantly reduce start-up times in situations where many participants   are being processed with data from a network-attached storage (NAS).   (#405 by @agramfort and @hoechenberger)</li> <li>Files docstrings in the preprocessing steps were updated.   (#409 by @crsegerie)</li> <li>Do not crash when concatenating epochs or raws with different measurement   info (like the dev_head_t when using EEG only data).   (#416 by @agramfort)</li> <li>The <code>run.py</code> command line interface gained a new parameter <code>--n_jobs</code> to   specify the number of processes to run in parallel.   (#417 by @hoechenberger)</li> <li>Great improvements to our logging system produce more readable output on the   terminal. We also generate an Excel file containing useful debugging info   for all participants at each processing step to help you spot problematic   participants more easily.   (#429), gh(441 by @agramfort @hoechenberger)</li> <li>It is now possible to specify from which file to load the <code>mne.Info</code> object   during forward and inverse computation via   <code>source_info_path_update</code>.   (#452 by @apmellot)</li> <li>The <code>run.py</code> command line interface gained a new parameter, <code>--interactive</code>,   allowing you to override the interactive mode setting from the configuration   file.   (#456), gh(457 by @hoechenberger)</li> <li>Add a new configuration setting <code>freesurfer_verbose</code>   to control whether to display of FreeSurfer output.   (#459 by @hoechenberger)</li> <li>The <code>noise_cov</code> option can now be set to <code>ad-hoc</code> to use   a fixed and data-independent diagonal noise covariance matrix for source   imaging.   (#460 by @agramfort and  @apmellot)</li> <li>Processing can now be parallelized using Dask. To use   Dask, set the new configuration setting <code>parallel_backend</code>   to <code>'dask'</code>.   (#472 by @agramfort and  @hoechenberger)</li> <li>Drastically reduce memory usage during the epoching and ICA steps.   (#477 by @hoechenberger and @agramfort)</li> <li>The new <code>plot_psd_for_runs</code> setting can be used   to control for which runs to add PSD plots of the raw data to the reports.   (#482 by @hoechenberger)</li> <li>Speed up report generation.   (#487 by @hoechenberger)</li> <li>The new `epochs_metadata_query setting   allows to select epochs based on metadata query strings.   (#495 by @hoechenberger and @agramfort)</li> <li>The new <code>time_frequency_cycles</code> setting   allows for customization of the number of Morlet wavelet cycles used in   time-frequency analysis.   (#516 by @hoechenberger)</li> <li>To analyze induced (as opposed to evoked) activity in the time-frequency   domain, the new setting   <code>time_frequency_subtract_evoked</code>   has been added, allowing to subtract the evoked signal from the epochs   before performing time-frequency analysis.   (#516 by @hoechenberger)</li> <li>The covariance matrix and corresponding SVD figures, as well as whitened   evoked data plots are now added to the reports.   (#532 by @hoechenberger)</li> <li>The <code>noise_cov</code> option can now be set to a function to   allow working with arbitrarily-generated covariance matrices.   (#535 by @hoechenberger and @agramfort)</li> <li>Arbitrary contrasts can be used in <code>contrasts</code>. The list   now accepts as valid items, in addition to tuples which kept their behavior,   dicts specifying a name, a condition list and a weights list to use to   <code>combine_evoked</code>. Decoding steps ignores contrasts with more than two   elements.   (#536 by @mathias-sm)</li> <li>The pipeline configuration and MNE system information are now automatically   added to the report.   (#544 by @hoechenberger)</li> <li>More robust empty-room data processing for use with Maxwell filter. We are   now relying on <code>mne.preprocessing.maxwell_filter_prepare_emptyroom</code>.   (#550 by @hoechenberger)</li> <li>Maxwell filtering now also parallelizes across runs (previously only across   subjects and sessions).   (#550 by @hoechenberger)</li> <li>It is now possible to estimate the noise covariance matrix based on a   resting-state recording and use it for inverse modeling, just like one could   previously do with empty-room recordings.   (#554 by @hoechenberger)</li> <li>Added full-epochs decoding.   (#558 by @hoechenberger)</li> <li>Generalization across time can now be enabled for the time-by-time decoding   scheme via the new configuration option   <code>decoding_time_generalization</code>.   (#559 by @hoechenberger)</li> <li>Generalization across time additional decimation can be configured using   <code>decoding_time_generalization_decim</code>.   (#603 by @larsoner)</li> <li>Caching of pipeline enabled for many pipeline steps   by default using <code>memory_location=True'</code>   (#563, #600, #608, #615, #618, #644 by @agramfort and @larsoner)</li> <li>Basic testing of infant MEG data with movement was added to CI testing   (#582 by @larsoner)</li> <li>The <code>loose</code> and <code>depth</code> configuration parameters were re-enabled   (#592) by @larsoner</li> <li>Add the example MIND DATA dataset (ds004107)   ((#600) by @larsoner)</li> <li>Simultaneous MEG+EEG can now be processed jointly   (#606 by @larsoner)</li> <li>Spatial filtering using SSP is now supported for EEG data   (#606 by @larsoner)</li> <li>Add SSP joint plots to generated reports</li> <li>(#614 by @larsoner)</li> <li>It is now possible to specify baseline and cropping parameters for   plotting time-frequency results via   <code>time_frequency_baseline</code>,   <code>time_frequency_baseline_mode</code>   and <code>time_frequency_crop</code>.   (#641 by @agramfort)</li> <li>Add time-frequency decoding based on common spatial patterns   (CSP).   (#625 by @crsegerie, @agramfort,   @hoechenberger, and @larsoner)</li> <li>Add progress bar for time-by-time decoding   (#647 by @larsoner)</li> <li>A template configuration file can now be created via <code>mne_bids_pipeline --create-config</code>   (#653 by @hoechenberger)</li> <li>Make report generation happen within relevant steps instead of at the end   of all steps   (#652 by @larsoner)</li> <li>Initial raw data plots are now added to reports and bad channel detection   is executed in a dedicated step   (#666 by @larsoner)</li> </ul>"},{"location":"changes.html#behavior-changes_3","title":"Behavior changes","text":"<ul> <li>The <code>conditions</code> setting will now be <code>None</code> by default.   It is a required setting so it will raise an error if left as <code>None</code>.   (#348 by @guiomar and @hoechenberger)</li> <li>When creating epochs, only those epochs are kept that belong to the specified   <code>conditions</code>. This means that only this subset of epochs   will be passed to ICA and SSP (if used). Previously, we would created epochs   based on all events found in the data, and only subset them to the requested   conditions at the epoching stage.   (#449 by @agramfort)</li> <li>Epochs rejection based on peak-to-peak amplitude, as controlled via the   <code>reject</code> setting, will now take place after ICA or SSP.   In previous versions of the Pipeline, rejection was carried out before ICA   and SSP. To exclude epochs from ICA fitting, use the new   <code>ica_reject</code> setting.</li> <li>We don't apply SSP by default anymore.   (#315 by @hoechenberger)</li> <li>The <code>use_ssp</code> and <code>use_ica</code> settings have been removed. Please use the new   <code>spatial_filter</code> setting instead.   (#315 by @hoechenberger)</li> <li>The <code>allow_maxshield</code> setting has been removed. The Pipeline now   automatically ensures that FIFF files of recordings with active   shielding (MaxShield) can be imported. Later stages of the Pipeline will fail   if Maxwell filtering of such data is disabled via <code>use_maxwell_filter=False</code>.   (#318 by @hoechenberger)</li> <li>The overlay plots that show the effects of ICA cleaning are now based on the   baseline-corrected data to make it easier to spot the differences.   (#320 by @hoechenberger)</li> <li><code>bids_root</code> and <code>deriv_root</code> are now converted to absolute paths to avoid   running into issues caused by relative path specifications.   (#322 by @hoechenberger)</li> <li>Warn if using ICA and no EOG- or ECG-related ICs were detected.   (#351 by @crsegerie)</li> <li>Added the possibility to have different runs for different subjects.   (#353 by @crsegerie))</li> <li>Check that the baseline interval falls into <code>[epochs_tmin, epochs_tmax]</code>.   (#361 by @crsegerie)</li> <li><code>config.crop</code> has been renamed to the more explicit   <code>config.crop_runs</code>, as it only applies to individual   runs and not the concatenated data.   (#358 by @hoechenberger)</li> <li><code>ica_reject</code> now also applies to ECG and EOG epochs.   (#373 by @crsegerie)</li> <li>Added a new step <code>freesurfer/coreg_surfaces</code> that creates the scalp surfaces   required for coregistration in MNE-Python.   (#422 by @hoechenberger)</li> <li>Enabling interactive mode by setting <code>interactive</code> to   <code>True</code> now deactivates parallel processing.   (#473 by @hoechenberger)</li> <li>The resolution of the MRI slices for BEM visualalization has been reduced to   256 by 256 pixels (was 512 by 512 before), we now only plot every 8th slice   (was ever 2nd before). This greatly speeds up BEM rendering and reduces the   size of the generated report, while maintaining a sufficiently detailed   visualization.   (#488 by @hoechenberger)</li> <li>In <code>interactive</code> mode, the Matplotlib <code>Agg</code> backend   will be used.   (#497 by @hoechenberger)</li> <li>We added new configuration options to control the number of time points to   use when creating topographic maps of evoked signals and brain plots for   source estimates:   <code>report_evoked_n_time_points</code> and   <code>report_stc_n_time_points</code>, respectively.   (#542 by @agramfort)</li> <li>Add <code>reader_extra_params</code> parameter to pass   parameters to read_raw_bids.   (#585 by @agramfort)</li> <li>Add <code>task_is_rest</code> parameter to be explicit that   the data must be analyzed as resting state.   (#585 by @agramfort)</li> <li>Patch information is now incorporated when computing surface source spaces,   which should slightly improve the surface normals   (#588 by @larsoner)</li> <li>Add <code>ssp_meg</code> option for MEG SSP computation. This   defaults to <code>'auto'</code>, which will use <code>ssp_meg='combined'</code> for SSP computation   when Maxwell filtering is used.   (#595 by @larsoner)</li> <li>Empty-room and resting-state data are processed by default if present,   regardless of <code>config.noise_cov</code> value.   This can be controlled by changing the default values from   <code>config.process_empty_room = True</code> and   <code>config.process_rest = True</code>   (#633 by @larsoner)</li> <li>Environment variables are no longer used to control execution and variables,   use command-line switches instead   (#663 by @larsoner )</li> <li>Config validation of likely misspellings and (some) outdated variables   are now checked   (#665, #670 by @larsoner )</li> </ul>"},{"location":"changes.html#code-health_6","title":"Code health","text":"<ul> <li>Each processing script now extracts the required subset of configuration   options from the user config and operates solely on these. This helps make it   clear which settings an individual script depends on.   (#383 by @agramfort and @hoechenberger)</li> <li>We laid the groundwork for applying the inverse operator on other data types   than just <code>mne.Evoked</code> by introducing   <code>inverse_targets</code>.   (#452 by @apmellot)</li> <li>All processing scripts have been renamed and turned into submodules, and the   pipeline is now organized like a standard Python package with a command-line   interface <code>mne_bids_pipeline ...</code>   (#470, #611, #664 by @agramfort,    @hoechenberger, and @larsoner)</li> <li>For storing configuration values, we switched from using <code>BunchConst</code> to   Python's built-in <code>SimpleNamespace</code>.   (#472 by @agramfort)</li> <li>The <code>config.process_er</code> variable was renamed   <code>config.process_empty_room</code>   for readability, and the default was changed to <code>True</code> for consistency   (#633 by @larsoner)</li> </ul>"},{"location":"changes.html#bug-fixes_4","title":"Bug fixes","text":"<ul> <li>The FreeSurfer script could only be run if <code>--n_jobs</code> was passed explicitly   (#287 by @MerlinDumeur)</li> <li>Fix a problem with the FreeSurfer processing step that caused the error   message <code>Could not consume arg</code> after completion (#301 by   @hoechenberger)</li> <li>Selecting the <code>extended_infomax</code> ICA algorithm caused a crash   (#308 by @hoechenberger)</li> <li>Correctly handle <code>eog_channels = None</code> setting after creation of bipolar EEG   channels   (#311 by @hoechenberger)</li> <li>Added instructions on how to handle <code>FileNotFoundError</code> when loading the BEM   model in the source steps (#304  by @MerlinDumeur)</li> <li>When using <code>find_noisy_channels_meg</code> or   <code>find_flat_channels_meg</code>, we now pass   <code>mf_head_origin</code> to the respective bad channel   detection algorithm to achieve better performance   (#319 by @agramfort)</li> <li>Baseline was not applied to epochs if neither ICA nor SSP was used   (#319 by @hoechenberger)</li> <li>Ensure we always use the cleaned epochs for constructing evoked data   (#319 by @agramfort)</li> <li>The summary report didn't use the cleaned epochs for showing the effects of   ICA.   (#320 by @hoechenberger)</li> <li>The sanity check comparing the rank of the experimental data and the rank of    the empty-room after Maxwell-filtering did not use the maxfiltered data.   (#336 by @agramfort, @hoechenberger,   and @crsegerie)</li> <li><code>epochs_tmin</code> and <code>epochs_tmax</code> were named incorrectly in some test config   files.   (#340 by @crsegerie)</li> <li>We now reject bad epochs by using <code>ica_reject</code> before   producing the \"overlay\" plots that show the evoked data before and after   ICA cleaning in the <code>proc-ica_report</code>.   (#385 by @crsegerie).</li> <li>Passing subject, session, task, and run names to <code>run.py</code> the consist only of   numbers doesn't throw an exception anymore, even if the values weren't   double-quoted and hence converted to strings by the command-line interface   toolkit we are using, Fire.   (#375 by @hoechenberger)</li> <li>Setting <code>eeg_reference</code> to a string (name of the   reference channel) caused us to crash.   (#391 by @hoechenberger)</li> <li>Parameters retrieved from the BIDS dataset were not limited to the modality   (\"data type\") we meant to process, sometimes leading to crashes.   (#391 by @hoechenberger)</li> <li>Fix forward computation for CTF data.   (#427 by @agramfort)</li> <li>Generated derivative epochs split files now follow the BIDS naming scheme.   (#463)}} by @dengemann)</li> <li>Report tags are now better sanitized.   (#471 by @hoechenberger)</li> <li>When creating epochs, we now ensure that the trigger codes provided via the   <code>*_events.tsv</code> file are retained; previously, new trigger codes were   generated in certain situations.   (#471 by @hoechenberger)</li> <li>ICA overlay plots in the report used the cleaned epochs, resulting in no   visible ICA cleaning effects. This has been corrected.   (#478 by @hoechenberger)</li> <li>Ensure we don't over-estimate the rank of Maxwell-filtered data consisting   of multiple runs.   (#530 by @hoechenberger and @agramfort)</li> <li>Don't drop bad channels from empty-room data on import.   (#532 by @hoechenberger)</li> <li>Time-by-time decoding now respects the   <code>decoding_n_splits</code> setting.   (#558 by @hoechenberger)</li> <li>Time-by-time decoding now respects the random seed specified via   <code>random_state</code> when generating the cross-validation   splits.   (#558 by @hoechenberger)</li> <li>When automatically finding flat or noisy MEG channels was enabled, the data   would always be 40-Hz-lowpass-filtered even if not explicitly requested by   the user. This is now fixed.   (#558 by @apmellot and @hoechenberger)</li> <li>EEG channels couldn't be used as \"virtual\" EOG channels during ICA artifact   detection. Reported by \"fraenni\" on the forum. Thank you! \ud83c\udf3b   (#572 by @hoechenberger)</li> <li>Fix bug with handling of split files during preprocessing   (#597 by @larsoner)</li> <li>Fix bug where wrong command-line arguments to <code>run.py</code> were just ignored   instead of raising an error   (#605) by @larsoner)</li> <li>During the Maxwell filtering step, all channels are now kept rather than   being restricted to just MEG channels   (#606 by @larsoner)</li> <li>The default for <code>analyze_channels</code> is now <code>'ch_types'</code> which restricts to the   data channels of interest rather than <code>'all'</code>, which included all channels,   and hence could include things like stimulus channels   (#606 by @larsoner)</li> <li>Fix bug where only the first run was used to compute SSP   (#607 by @larsoner)</li> <li>Fix bug with CPU oversubscription when using the Dask backend on macOS M1   (#638 by @larsoner)</li> </ul>"},{"location":"governance.html","title":"Governance","text":"<p>We follow the same governance model as MNE-Python with the exception that the Steering Council and Institutional Partners differ, see below.</p>"},{"location":"governance.html#steering-council","title":"Steering Council","text":"<ul> <li>Alex Gramfort</li> <li>Richard H\u00f6chenberger</li> </ul>"},{"location":"governance.html#institutional-partners","title":"Institutional Partners","text":"<ul> <li>Inria</li> </ul>"},{"location":"tags.html","title":"Tags","text":""},{"location":"tags.html#artifact-removal","title":"artifact-removal","text":"<ul> <li>Amplitude-based artifact rejection</li> <li>Break detection</li> <li>SSP &amp; ICA</li> <li>Stimulation artifact</li> </ul>"},{"location":"tags.html#bad-channels","title":"bad-channels","text":"<ul> <li>Bad channel detection</li> </ul>"},{"location":"tags.html#bem","title":"bem","text":"<ul> <li>BEM surface</li> </ul>"},{"location":"tags.html#contrast","title":"contrast","text":"<ul> <li>Condition contrasts</li> <li>Decoding / MVPA</li> </ul>"},{"location":"tags.html#decimation","title":"decimation","text":"<ul> <li>Resampling</li> </ul>"},{"location":"tags.html#decoding","title":"decoding","text":"<ul> <li>Decoding / MVPA</li> </ul>"},{"location":"tags.html#epochs","title":"epochs","text":"<ul> <li>Amplitude-based artifact rejection</li> <li>Epoching</li> <li>Resampling</li> <li>SSP &amp; ICA</li> <li>Stimulation artifact</li> <li>Condition contrasts</li> <li>Decoding / MVPA</li> <li>Time-frequency analysis</li> </ul>"},{"location":"tags.html#events","title":"events","text":"<ul> <li>Break detection</li> <li>Epoching</li> </ul>"},{"location":"tags.html#evoked","title":"evoked","text":"<ul> <li>Condition contrasts</li> <li>Group-level analysis</li> <li>Decoding / MVPA</li> <li>Time-frequency analysis</li> </ul>"},{"location":"tags.html#forward-model","title":"forward-model","text":"<ul> <li>Source space &amp; forward solution</li> </ul>"},{"location":"tags.html#freesurfer","title":"freesurfer","text":"<ul> <li>BEM surface</li> </ul>"},{"location":"tags.html#frequency-filter","title":"frequency-filter","text":"<ul> <li>Filtering</li> </ul>"},{"location":"tags.html#group-level","title":"group-level","text":"<ul> <li>Group-level analysis</li> </ul>"},{"location":"tags.html#ica","title":"ica","text":"<ul> <li>SSP &amp; ICA</li> </ul>"},{"location":"tags.html#inverse-solution","title":"inverse-solution","text":"<ul> <li>BEM surface</li> <li>Source space &amp; forward solution</li> <li>General settings</li> <li>Inverse solution</li> </ul>"},{"location":"tags.html#maxwell-filter","title":"maxwell-filter","text":"<ul> <li>Maxwell filter</li> </ul>"},{"location":"tags.html#metadata","title":"metadata","text":"<ul> <li>Epoching</li> </ul>"},{"location":"tags.html#mvpa","title":"mvpa","text":"<ul> <li>Decoding / MVPA</li> </ul>"},{"location":"tags.html#preprocessing","title":"preprocessing","text":"<ul> <li>Amplitude-based artifact rejection</li> <li>Bad channel detection</li> <li>Break detection</li> <li>Epoching</li> <li>Filtering</li> <li>Maxwell filter</li> <li>Resampling</li> <li>SSP &amp; ICA</li> <li>Stimulation artifact</li> </ul>"},{"location":"tags.html#raw","title":"raw","text":"<ul> <li>Bad channel detection</li> <li>Break detection</li> <li>Filtering</li> <li>Maxwell filter</li> <li>Resampling</li> <li>SSP &amp; ICA</li> <li>Stimulation artifact</li> </ul>"},{"location":"tags.html#report","title":"report","text":"<ul> <li>Report generation</li> </ul>"},{"location":"tags.html#resampling","title":"resampling","text":"<ul> <li>Resampling</li> </ul>"},{"location":"tags.html#resting-state","title":"resting-state","text":"<ul> <li>Epoching</li> </ul>"},{"location":"tags.html#ssp","title":"ssp","text":"<ul> <li>SSP &amp; ICA</li> </ul>"},{"location":"tags.html#time-frequency","title":"time-frequency","text":"<ul> <li>Time-frequency analysis</li> </ul>"},{"location":"examples/ERP_CORE.html","title":"ERP CORE","text":"<p>This example demonstrate how to process 5 participants from the ERP CORE dataset. It shows how to obtain 7 ERP components from a total of 6 experimental tasks:</p> <ul> <li>N170 (face perception)</li> <li>MMN (passive auditory oddball)</li> <li>N2pc (visual search)</li> <li>N400 (word pair judgment)</li> <li>P3b (active visual oddball)</li> <li>LRP and ERN (flankers task)</li> </ul>"},{"location":"examples/ERP_CORE.html#dataset-information","title":"Dataset information","text":"<ul> <li>Authors: Emily S. Kappenman, Jaclyn L. Farrens, Wendy Zhang,                        Andrew X. Stewart, and Steven J. Luck</li> <li>License: CC-BY-4.0</li> <li>URL: https://erpinfo.org/erp-core</li> <li>Citation: Kappenman, E., Farrens, J., Zhang, W., Stewart, A. X.,                 &amp; Luck, S. J. (2021). ERP CORE: An open resource for human                 event-related potential research. NeuroImage 225: 117465.                 https://doi.org/10.1016/j.neuroimage.2020.117465</li> </ul>"},{"location":"examples/ERP_CORE.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-generalization decoding \u2705 CSP decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/ERP_CORE.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://osf.io/3zk6n/download?version=2</p>"},{"location":"examples/ERP_CORE.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>import argparse\nimport mne\nimport sys\n\nstudy_name = \"ERP-CORE\"\nbids_root = \"~/mne_data/ERP_CORE\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ERP_CORE\"\n\n# Find the --task option\nargs = [arg for arg in sys.argv if arg.startswith(\"--task\") or not arg.startswith(\"-\")]\nparser = argparse.ArgumentParser()\nparser.add_argument(\"ignored\", nargs=\"*\")\nparser.add_argument(\n    \"--task\", choices=(\"N400\", \"ERN\", \"LRP\", \"MMN\", \"N2pc\", \"N170\", \"P3\"), required=True\n)\ntask = parser.parse_args(args).task\nsessions = [task]\n\nsubjects = [\"015\", \"016\", \"017\", \"018\", \"019\"]\n\nch_types = [\"eeg\"]\ninteractive = False\n\nraw_resample_sfreq = 128\n# Suppress \"Data file name in EEG.data (sub-019_task-ERN_eeg.fdt) is incorrect...\"\nread_raw_bids_verbose = \"error\"\n\neeg_template_montage = mne.channels.make_standard_montage(\"standard_1005\")\neeg_bipolar_channels = {\n    \"HEOG\": (\"HEOG_left\", \"HEOG_right\"),\n    \"VEOG\": (\"VEOG_lower\", \"FP2\"),\n}\ndrop_channels = [\"HEOG_left\", \"HEOG_right\", \"VEOG_lower\"]\neog_channels = [\"HEOG\", \"VEOG\"]\n\nl_freq = 0.1\nh_freq = None\nnotch_freq = 60\n\ndecode = True\ndecoding_time_generalization = True\ndecoding_time_generalization_decim = 2\n\nfind_breaks = True\nmin_break_duration = 10\nt_break_annot_start_after_previous_event = 3.0\nt_break_annot_stop_before_next_event = 1.5\n\nif task == \"N400\":  # test autoreject local without ICA\n    spatial_filter = None\n    reject = \"autoreject_local\"\n    autoreject_n_interpolate = [2, 4]\nelif task == \"N170\":  # test autoreject local before ICA\n    spatial_filter = \"ica\"\n    ica_reject = \"autoreject_local\"\n    reject = \"autoreject_global\"\n    autoreject_n_interpolate = [2, 4]\nelse:\n    spatial_filter = \"ica\"\n    ica_reject = dict(eeg=350e-6, eog=500e-6)\n    reject = \"autoreject_global\"\n\n# These settings are only used for the cases where spatial_filter=\"ica\"\nica_max_iterations = 1000\nica_eog_threshold = 2\nica_decim = 2  # speed up ICA fitting\n\nrun_source_estimation = False\non_rename_missing_events = \"ignore\"\n\nparallel_backend = \"dask\"\ndask_worker_memory_limit = \"2G\"\nn_jobs = 4\n\nif task == \"N400\":\n    dask_open_dashboard = True\n\n    rename_events = {\n        \"response/201\": \"response/correct\",\n        \"response/202\": \"response/error\",\n        \"stimulus/111\": \"stimulus/prime/related\",\n        \"stimulus/112\": \"stimulus/prime/related\",\n        \"stimulus/121\": \"stimulus/prime/unrelated\",\n        \"stimulus/122\": \"stimulus/prime/unrelated\",\n        \"stimulus/211\": \"stimulus/target/related\",\n        \"stimulus/212\": \"stimulus/target/related\",\n        \"stimulus/221\": \"stimulus/target/unrelated\",\n        \"stimulus/222\": \"stimulus/target/unrelated\",\n    }\n\n    eeg_reference = [\"P9\", \"P10\"]\n    epochs_tmin = -0.2\n    epochs_tmax = 0.8\n    epochs_metadata_tmin = 0\n    epochs_metadata_tmax = 1.5\n    epochs_metadata_keep_first = [\"stimulus/target\", \"response\"]\n    baseline = (None, 0)\n\n    conditions = {\n        \"related\": '`first_stimulus/target` == \"related\" and '\n        'first_response == \"correct\"',\n        \"unrelated\": '`first_stimulus/target` == \"unrelated\" and '\n        'first_response == \"correct\"',\n    }\n    contrasts = [(\"unrelated\", \"related\")]\n    cluster_forming_t_threshold = 1.5  # Only for testing!\n    cluster_permutation_p_threshold = 0.2  # Only for testing!\nelif task == \"ERN\":\n    rename_events = {\n        \"stimulus/11\": \"compatible/left\",\n        \"stimulus/12\": \"compatible/right\",\n        \"stimulus/21\": \"incompatible/left\",\n        \"stimulus/22\": \"incompatible/right\",\n        \"response/111\": \"response/correct\",\n        \"response/112\": \"response/incorrect\",\n        \"response/121\": \"response/correct\",\n        \"response/122\": \"response/incorrect\",\n        \"response/211\": \"response/incorrect\",\n        \"response/212\": \"response/correct\",\n        \"response/221\": \"response/incorrect\",\n        \"response/222\": \"response/correct\",\n    }\n\n    eeg_reference = [\"P9\", \"P10\"]\n    ica_n_components = 30 - len(eeg_reference)\n    epochs_tmin = -0.6\n    epochs_tmax = 0.4\n    baseline = (-0.4, -0.2)\n    conditions = [\"response/correct\", \"response/incorrect\"]\n    contrasts = [(\"response/incorrect\", \"response/correct\")]\n    cluster_forming_t_threshold = 5  # Only for testing!\n    cluster_permutation_p_threshold = 0.2  # Only for testing!\n    decoding_csp = True\n    decoding_csp_freqs = {\n        \"theta\": [4, 7],\n        \"alpha\": [8, 12],\n        \"beta\": [13, 20, 30],\n        \"gamma\": [50, 63],\n    }\n    decoding_csp_times = [-0.2, 0.0, 0.2, 0.4]\nelif task == \"LRP\":\n    rename_events = {\n        \"stimulus/11\": \"compatible/left\",\n        \"stimulus/12\": \"compatible/right\",\n        \"stimulus/21\": \"incompatible/left\",\n        \"stimulus/22\": \"incompatible/right\",\n        \"response/111\": \"response/left/correct\",\n        \"response/112\": \"response/left/incorrect\",\n        \"response/121\": \"response/left/correct\",\n        \"response/122\": \"response/left/incorrect\",\n        \"response/211\": \"response/right/incorrect\",\n        \"response/212\": \"response/right/correct\",\n        \"response/221\": \"response/right/incorrect\",\n        \"response/222\": \"response/right/correct\",\n    }\n\n    eeg_reference = [\"P9\", \"P10\"]\n    ica_n_components = 30 - len(eeg_reference)\n    epochs_tmin = -0.8\n    epochs_tmax = 0.2\n    baseline = (None, -0.6)\n    conditions = [\"response/left\", \"response/right\"]\n    contrasts = [(\"response/right\", \"response/left\")]  # contralateral vs ipsi\nelif task == \"MMN\":\n    rename_events = {\n        \"stimulus/70\": \"stimulus/deviant\",\n        \"stimulus/80\": \"stimulus/standard\",\n    }\n\n    eeg_reference = [\"P9\", \"P10\"]\n    ica_n_components = 30 - len(eeg_reference)\n    epochs_tmin = -0.2\n    epochs_tmax = 0.8\n    baseline = (None, 0)\n    conditions = [\"stimulus/standard\", \"stimulus/deviant\"]\n    contrasts = [(\"stimulus/deviant\", \"stimulus/standard\")]\nelif task == \"N2pc\":\n    rename_events = {\n        \"response/201\": \"response/correct\",\n        \"response/202\": \"response/error\",\n        \"stimulus/111\": \"stimulus/blue/left\",\n        \"stimulus/112\": \"stimulus/blue/left\",\n        \"stimulus/121\": \"stimulus/blue/right\",\n        \"stimulus/122\": \"stimulus/blue/right\",\n        \"stimulus/211\": \"stimulus/pink/left\",\n        \"stimulus/212\": \"stimulus/pink/left\",\n        \"stimulus/221\": \"stimulus/pink/right\",\n        \"stimulus/222\": \"stimulus/pink/right\",\n    }\n\n    eeg_reference = [\"P9\", \"P10\"]\n    ica_n_components = 30 - len(eeg_reference)\n    epochs_tmin = -0.2\n    epochs_tmax = 0.8\n    baseline = (None, 0)\n    conditions = [\"stimulus/right\", \"stimulus/left\"]\n    contrasts = [(\"stimulus/right\", \"stimulus/left\")]  # Contralteral vs ipsi\nelif task == \"N170\":\n    rename_events = {\n        \"response/201\": \"response/correct\",\n        \"response/202\": \"response/error\",\n    }\n\n    eeg_reference = \"average\"\n    ica_n_components = 30 - 1\n    for i in range(1, 180 + 1):\n        orig_name = f\"stimulus/{i}\"\n\n        if 1 &lt;= i &lt;= 40:\n            new_name = \"stimulus/face/normal\"\n        elif 41 &lt;= i &lt;= 80:\n            new_name = \"stimulus/car/normal\"\n        elif 101 &lt;= i &lt;= 140:\n            new_name = \"stimulus/face/scrambled\"\n        elif 141 &lt;= i &lt;= 180:\n            new_name = \"stimulus/car/scrambled\"\n        else:\n            continue\n\n        rename_events[orig_name] = new_name\n\n    epochs_tmin = -0.2\n    epochs_tmax = 0.8\n    baseline = (None, 0)\n    conditions = [\"stimulus/face/normal\", \"stimulus/car/normal\"]\n    contrasts = [(\"stimulus/face/normal\", \"stimulus/car/normal\")]\nelif task == \"P3\":\n    rename_events = {\n        \"response/201\": \"response/correct\",\n        \"response/202\": \"response/incorrect\",\n        \"stimulus/11\": \"stimulus/target/11\",\n        \"stimulus/22\": \"stimulus/target/22\",\n        \"stimulus/33\": \"stimulus/target/33\",\n        \"stimulus/44\": \"stimulus/target/44\",\n        \"stimulus/55\": \"stimulus/target/55\",\n        \"stimulus/21\": \"stimulus/non-target/21\",\n        \"stimulus/31\": \"stimulus/non-target/31\",\n        \"stimulus/41\": \"stimulus/non-target/41\",\n        \"stimulus/51\": \"stimulus/non-target/51\",\n        \"stimulus/12\": \"stimulus/non-target/12\",\n        \"stimulus/32\": \"stimulus/non-target/32\",\n        \"stimulus/42\": \"stimulus/non-target/42\",\n        \"stimulus/52\": \"stimulus/non-target/52\",\n        \"stimulus/13\": \"stimulus/non-target/13\",\n        \"stimulus/23\": \"stimulus/non-target/23\",\n        \"stimulus/43\": \"stimulus/non-target/43\",\n        \"stimulus/53\": \"stimulus/non-target/53\",\n        \"stimulus/14\": \"stimulus/non-target/14\",\n        \"stimulus/24\": \"stimulus/non-target/24\",\n        \"stimulus/34\": \"stimulus/non-target/34\",\n        \"stimulus/54\": \"stimulus/non-target/54\",\n        \"stimulus/15\": \"stimulus/non-target/15\",\n        \"stimulus/25\": \"stimulus/non-target/25\",\n        \"stimulus/35\": \"stimulus/non-target/35\",\n        \"stimulus/45\": \"stimulus/non-target/45\",\n    }\n\n    eeg_reference = [\"P9\", \"P10\"]\n    ica_n_components = 30 - len(eeg_reference)\n    epochs_tmin = -0.2\n    epochs_tmax = 0.8\n    baseline = (None, 0)\n    conditions = [\"stimulus/target\", \"stimulus/non-target\"]\n    contrasts = [(\"stimulus/target\", \"stimulus/non-target\")]\n    cluster_forming_t_threshold = 0.8  # Only for testing!\n    cluster_permutation_p_threshold = 0.2  # Only for testing!\nelse:\n    raise RuntimeError(f\"Task {task} not currently supported\")\n</code></pre>"},{"location":"examples/ERP_CORE.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-015_ses-ERN_task-ERN_report.html </p> <p>sub-015_ses-LRP_task-LRP_report.html </p> <p>sub-015_ses-MMN_task-MMN_report.html </p> <p>sub-015_ses-N170_task-N170_report.html </p> <p>sub-015_ses-N2pc_task-N2pc_report.html </p> <p>sub-015_ses-N400_task-N400_report.html </p> <p>sub-015_ses-P3_task-P3_report.html </p> <p>sub-016_ses-ERN_task-ERN_report.html </p> <p>sub-016_ses-LRP_task-LRP_report.html </p> <p>sub-016_ses-MMN_task-MMN_report.html </p> <p>sub-016_ses-N170_task-N170_report.html </p> <p>sub-016_ses-N2pc_task-N2pc_report.html </p> <p>sub-016_ses-N400_task-N400_report.html </p> <p>sub-016_ses-P3_task-P3_report.html </p> <p>sub-017_ses-ERN_task-ERN_report.html </p> <p>sub-017_ses-LRP_task-LRP_report.html </p> <p>sub-017_ses-MMN_task-MMN_report.html </p> <p>sub-017_ses-N170_task-N170_report.html </p> <p>sub-017_ses-N2pc_task-N2pc_report.html </p> <p>sub-017_ses-N400_task-N400_report.html </p> <p>sub-017_ses-P3_task-P3_report.html </p> <p>sub-018_ses-ERN_task-ERN_report.html </p> <p>sub-018_ses-LRP_task-LRP_report.html </p> <p>sub-018_ses-MMN_task-MMN_report.html </p> <p>sub-018_ses-N170_task-N170_report.html </p> <p>sub-018_ses-N2pc_task-N2pc_report.html </p> <p>sub-018_ses-N400_task-N400_report.html </p> <p>sub-018_ses-P3_task-P3_report.html </p> <p>sub-019_ses-ERN_task-ERN_report.html </p> <p>sub-019_ses-LRP_task-LRP_report.html </p> <p>sub-019_ses-MMN_task-MMN_report.html </p> <p>sub-019_ses-N170_task-N170_report.html </p> <p>sub-019_ses-N2pc_task-N2pc_report.html </p> <p>sub-019_ses-N400_task-N400_report.html </p> <p>sub-019_ses-P3_task-P3_report.html </p> <p>sub-average_ses-ERN_task-ERN_report.html </p> <p>sub-average_ses-LRP_task-LRP_report.html </p> <p>sub-average_ses-MMN_task-MMN_report.html </p> <p>sub-average_ses-N170_task-N170_report.html </p> <p>sub-average_ses-N2pc_task-N2pc_report.html </p> <p>sub-average_ses-N400_task-N400_report.html </p> <p>sub-average_ses-P3_task-P3_report.html </p> Data cleaning <p>sub-015_ses-ERN_task-ERN_proc-ica+components_report.html </p> <p>sub-015_ses-ERN_task-ERN_proc-ica_report.html </p> <p>sub-015_ses-LRP_task-LRP_proc-ica+components_report.html </p> <p>sub-015_ses-LRP_task-LRP_proc-ica_report.html </p> <p>sub-015_ses-MMN_task-MMN_proc-ica+components_report.html </p> <p>sub-015_ses-MMN_task-MMN_proc-ica_report.html </p> <p>sub-015_ses-N170_task-N170_proc-ica+components_report.html </p> <p>sub-015_ses-N170_task-N170_proc-ica_report.html </p> <p>sub-015_ses-N2pc_task-N2pc_proc-ica+components_report.html </p> <p>sub-015_ses-N2pc_task-N2pc_proc-ica_report.html </p> <p>sub-015_ses-P3_task-P3_proc-ica+components_report.html </p> <p>sub-015_ses-P3_task-P3_proc-ica_report.html </p> <p>sub-016_ses-ERN_task-ERN_proc-ica+components_report.html </p> <p>sub-016_ses-ERN_task-ERN_proc-ica_report.html </p> <p>sub-016_ses-LRP_task-LRP_proc-ica+components_report.html </p> <p>sub-016_ses-LRP_task-LRP_proc-ica_report.html </p> <p>sub-016_ses-MMN_task-MMN_proc-ica+components_report.html </p> <p>sub-016_ses-MMN_task-MMN_proc-ica_report.html </p> <p>sub-016_ses-N170_task-N170_proc-ica+components_report.html </p> <p>sub-016_ses-N170_task-N170_proc-ica_report.html </p> <p>sub-016_ses-N2pc_task-N2pc_proc-ica+components_report.html </p> <p>sub-016_ses-N2pc_task-N2pc_proc-ica_report.html </p> <p>sub-016_ses-P3_task-P3_proc-ica+components_report.html </p> <p>sub-016_ses-P3_task-P3_proc-ica_report.html </p> <p>sub-017_ses-ERN_task-ERN_proc-ica+components_report.html </p> <p>sub-017_ses-ERN_task-ERN_proc-ica_report.html </p> <p>sub-017_ses-LRP_task-LRP_proc-ica+components_report.html </p> <p>sub-017_ses-LRP_task-LRP_proc-ica_report.html </p> <p>sub-017_ses-MMN_task-MMN_proc-ica+components_report.html </p> <p>sub-017_ses-MMN_task-MMN_proc-ica_report.html </p> <p>sub-017_ses-N170_task-N170_proc-ica+components_report.html </p> <p>sub-017_ses-N170_task-N170_proc-ica_report.html </p> <p>sub-017_ses-N2pc_task-N2pc_proc-ica+components_report.html </p> <p>sub-017_ses-N2pc_task-N2pc_proc-ica_report.html </p> <p>sub-017_ses-P3_task-P3_proc-ica+components_report.html </p> <p>sub-017_ses-P3_task-P3_proc-ica_report.html </p> <p>sub-018_ses-ERN_task-ERN_proc-ica+components_report.html </p> <p>sub-018_ses-ERN_task-ERN_proc-ica_report.html </p> <p>sub-018_ses-LRP_task-LRP_proc-ica+components_report.html </p> <p>sub-018_ses-LRP_task-LRP_proc-ica_report.html </p> <p>sub-018_ses-MMN_task-MMN_proc-ica+components_report.html </p> <p>sub-018_ses-MMN_task-MMN_proc-ica_report.html </p> <p>sub-018_ses-N170_task-N170_proc-ica+components_report.html </p> <p>sub-018_ses-N170_task-N170_proc-ica_report.html </p> <p>sub-018_ses-N2pc_task-N2pc_proc-ica+components_report.html </p> <p>sub-018_ses-N2pc_task-N2pc_proc-ica_report.html </p> <p>sub-018_ses-P3_task-P3_proc-ica+components_report.html </p> <p>sub-018_ses-P3_task-P3_proc-ica_report.html </p> <p>sub-019_ses-ERN_task-ERN_proc-ica+components_report.html </p> <p>sub-019_ses-ERN_task-ERN_proc-ica_report.html </p> <p>sub-019_ses-LRP_task-LRP_proc-ica+components_report.html </p> <p>sub-019_ses-LRP_task-LRP_proc-ica_report.html </p> <p>sub-019_ses-MMN_task-MMN_proc-ica+components_report.html </p> <p>sub-019_ses-MMN_task-MMN_proc-ica_report.html </p> <p>sub-019_ses-N170_task-N170_proc-ica+components_report.html </p> <p>sub-019_ses-N170_task-N170_proc-ica_report.html </p> <p>sub-019_ses-N2pc_task-N2pc_proc-ica+components_report.html </p> <p>sub-019_ses-N2pc_task-N2pc_proc-ica_report.html </p> <p>sub-019_ses-P3_task-P3_proc-ica+components_report.html </p> <p>sub-019_ses-P3_task-P3_proc-ica_report.html </p>"},{"location":"examples/ds000117.html","title":"Faces dataset","text":""},{"location":"examples/ds000117.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-generalization decoding \u2705 CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/ds000117.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds000117</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds000117 \\\n             --include=sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_* \\\n             --include=sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-02_* \\\n             --include=sub-01/ses-meg/meg/sub-01_ses-meg_headshape.pos \\\n             --include=sub-01/ses-meg/*.tsv \\\n             --include=sub-01/ses-meg/*.json \\\n             --include=sub-emptyroom/ses-20090409 \\\n             --include=derivatives/meg_derivatives/ct_sparse.fif \\\n             --include=derivatives/meg_derivatives/sss_cal.dat\n</code></pre></p>"},{"location":"examples/ds000117.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>study_name = \"ds000117\"\nbids_root = \"~/mne_data/ds000117\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds000117\"\n\ntask = \"facerecognition\"\nch_types = [\"meg\"]\nruns = [\"01\", \"02\"]\nsessions = [\"meg\"]\nsubjects = [\"01\"]\n\nraw_resample_sfreq = 125.0\ncrop_runs = (0, 300)  # Reduce memory usage on CI system\n\nfind_flat_channels_meg = True\nfind_noisy_channels_meg = True\nuse_maxwell_filter = True\n\nmf_reference_run = \"02\"\nmf_cal_fname = bids_root + \"/derivatives/meg_derivatives/sss_cal.dat\"\nmf_ctc_fname = bids_root + \"/derivatives/meg_derivatives/ct_sparse.fif\"\n\nreject = {\"grad\": 4000e-13, \"mag\": 4e-12}\nconditions = [\"Famous\", \"Unfamiliar\", \"Scrambled\"]\ncontrasts = [\n    (\"Famous\", \"Scrambled\"),\n    (\"Unfamiliar\", \"Scrambled\"),\n    (\"Famous\", \"Unfamiliar\"),\n]\n\ndecode = True\ndecoding_time_generalization = True\n\nrun_source_estimation = False\n</code></pre>"},{"location":"examples/ds000117.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-01_ses-meg_task-facerecognition_report.html </p> <p>sub-average_ses-meg_task-facerecognition_report.html </p>"},{"location":"examples/ds000246.html","title":"Brainstorm - Auditory Dataset.","text":"<p>See https://openneuro.org/datasets/ds000246/versions/1.0.0 for more information.</p>"},{"location":"examples/ds000246.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-generalization decoding \u2705 CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/ds000246.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds000246</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds000246 \\\n             --include=sub-0001/meg/sub-0001_task-AEF_run-01_meg.ds \\\n             --include=sub-0001/meg/sub-0001_task-AEF_run-01_meg.json \\\n             --include=sub-0001/meg/sub-0001_task-AEF_run-01_channels.tsv\n</code></pre></p>"},{"location":"examples/ds000246.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>study_name = \"ds000246\"\nbids_root = \"~/mne_data/ds000246\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds000246\"\n\nruns = [\"01\"]\ncrop_runs = (0, 120)  # Reduce memory usage on CI system\nread_raw_bids_verbose = \"error\"  # No BIDS -&gt; MNE mapping found for channel ...\nl_freq = 0.3\nh_freq = 100\nepochs_decim = 4\nsubjects = [\"0001\"]\nch_types = [\"meg\"]\nreject = dict(mag=4e-12, eog=250e-6)\nconditions = [\"standard\", \"deviant\", \"button\"]\ncontrasts = [(\"deviant\", \"standard\")]\ndecode = True\ndecoding_time_generalization = True\ndecoding_time_generalization_decim = 4\non_error = \"abort\"\nplot_psd_for_runs = []  # too much memory on CIs\n\nparallel_backend = \"dask\"\ndask_worker_memory_limit = \"2G\"\ndask_temp_dir = \"./.dask-worker-space\"\ndask_open_dashboard = True\nn_jobs = 2\n</code></pre>"},{"location":"examples/ds000246.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-0001_task-AEF_report.html </p> <p>sub-average_task-AEF_report.html </p>"},{"location":"examples/ds000247.html","title":"OMEGA Resting State Sample Data","text":""},{"location":"examples/ds000247.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u2705 ICA \u274c Evoked contrasts \u274c Time-by-time decoding \u274c Time-generalization decoding \u274c CSP decoding \u274c Time-frequency analysis \u2705 BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/ds000247.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds000247</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds000247 \\\n             --include=sub-0002/ses-01/meg\n</code></pre></p>"},{"location":"examples/ds000247.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>import numpy as np\n\n\nstudy_name = \"ds000247\"\nbids_root = f\"~/mne_data/{study_name}\"\nderiv_root = f\"~/mne_data/derivatives/mne-bids-pipeline/{study_name}\"\n\nsubjects = [\"0002\"]\nsessions = [\"01\"]\ntask = \"rest\"\ntask_is_rest = True\n\ncrop_runs = (0, 100)  # to speed up computations\n\nch_types = [\"meg\"]\nspatial_filter = \"ssp\"\n\nl_freq = 1.0\nh_freq = 40.0\n\nrest_epochs_duration = 10\nrest_epochs_overlap = 0\n\nepochs_tmin = 0\nbaseline = None\n\ntime_frequency_conditions = [\"rest\"]\ntime_frequency_freq_min = 1.0\ntime_frequency_freq_max = 30.0\ntime_frequency_cycles = np.arange(time_frequency_freq_min, time_frequency_freq_max) / 4\ntime_frequency_subtract_evoked = True\n</code></pre>"},{"location":"examples/ds000247.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-0002_ses-01_task-rest_report.html </p>"},{"location":"examples/ds000248_FLASH_BEM.html","title":"MNE Sample Data: BEM from FLASH images","text":""},{"location":"examples/ds000248_FLASH_BEM.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u274c Time-by-time decoding \u274c Time-generalization decoding \u274c CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u2705 Template MRI \u274c"},{"location":"examples/ds000248_FLASH_BEM.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds000248</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds000248 \\\n             --include=sub-01 \\\n             --include=sub-emptyroom \\\n             --include=derivatives/freesurfer/subjects \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2005s+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2009s+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/xhemi/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.a2009s+aseg.mgz\n</code></pre></p> <p>Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage.</p>"},{"location":"examples/ds000248_FLASH_BEM.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>study_name = \"ds000248\"\nbids_root = \"~/mne_data/ds000248\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds000248_FLASH_BEM\"\nsubjects_dir = f\"{bids_root}/derivatives/freesurfer/subjects\"\n\nsubjects = [\"01\"]\nconditions = [\"Auditory\"]\n\nch_types = [\"meg\"]\n\nbem_mri_images = \"FLASH\"\nrecreate_bem = True\n</code></pre>"},{"location":"examples/ds000248_FLASH_BEM.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-01_task-audiovisual_report.html </p>"},{"location":"examples/ds000248_T1_BEM.html","title":"MNE Sample Data: BEM from T1 images","text":""},{"location":"examples/ds000248_T1_BEM.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u274c Time-by-time decoding \u274c Time-generalization decoding \u274c CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u2705 Template MRI \u274c"},{"location":"examples/ds000248_T1_BEM.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds000248</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds000248 \\\n             --include=sub-01 \\\n             --include=sub-emptyroom \\\n             --include=derivatives/freesurfer/subjects \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2005s+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2009s+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/xhemi/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.a2009s+aseg.mgz\n</code></pre></p> <p>Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage.</p>"},{"location":"examples/ds000248_T1_BEM.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>study_name = \"ds000248\"\nbids_root = \"~/mne_data/ds000248\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds000248_T1_BEM\"\nsubjects_dir = f\"{bids_root}/derivatives/freesurfer/subjects\"\n\nsubjects = [\"01\"]\nconditions = [\"Auditory\"]\n\nch_types = [\"meg\"]\n\nbem_mri_images = \"T1\"\nrecreate_bem = True\nfreesurfer_verbose = True  # Prevent the CI from canceling the job prematurely\n</code></pre>"},{"location":"examples/ds000248_T1_BEM.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-01_task-audiovisual_report.html </p>"},{"location":"examples/ds000248_base.html","title":"MNE Sample Data: M/EEG combined processing","text":""},{"location":"examples/ds000248_base.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u2705 EEG processing \u2705 Maxwell filter \u2705 Frequency filter \u2705 SSP \u2705 ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-generalization decoding \u274c CSP decoding \u274c Time-frequency analysis \u2705 BEM surface creation \u2705 Template MRI \u274c"},{"location":"examples/ds000248_base.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds000248</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds000248 \\\n             --include=sub-01 \\\n             --include=sub-emptyroom \\\n             --include=derivatives/freesurfer/subjects \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2005s+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2009s+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/xhemi/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.a2009s+aseg.mgz\n</code></pre></p> <p>Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage.</p>"},{"location":"examples/ds000248_base.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>import mne\n\nstudy_name = \"ds000248\"\nbids_root = \"~/mne_data/ds000248\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds000248_base\"\nsubjects_dir = f\"{bids_root}/derivatives/freesurfer/subjects\"\n\nsubjects = [\"01\"]\nrename_events = {\"Smiley\": \"Emoji\", \"Button\": \"Switch\"}\nconditions = [\"Auditory\", \"Visual\", \"Auditory/Left\", \"Auditory/Right\"]\nepochs_metadata_query = \"index &gt; 0\"  # Just for testing!\ncontrasts = [(\"Visual\", \"Auditory\"), (\"Auditory/Right\", \"Auditory/Left\")]\n\ntime_frequency_conditions = [\"Auditory\", \"Visual\"]\n\nch_types = [\"meg\", \"eeg\"]\nmf_reference_run = \"01\"\nfind_flat_channels_meg = True\nfind_noisy_channels_meg = True\nuse_maxwell_filter = True\n\n\ndef noise_cov(bp):\n    # Use pre-stimulus period as noise source\n    bp = bp.copy().update(processing=\"clean\", suffix=\"epo\")\n    if not bp.fpath.exists():\n        bp.update(split=\"01\")\n    epo = mne.read_epochs(bp)\n    cov = mne.compute_covariance(epo, rank=\"info\", tmax=0)\n    return cov\n\n\nspatial_filter = \"ssp\"\nn_proj_eog = dict(n_mag=1, n_grad=1, n_eeg=1)\nn_proj_ecg = dict(n_mag=1, n_grad=1, n_eeg=0)\nssp_meg = \"combined\"\necg_proj_from_average = True\neog_proj_from_average = False\nepochs_decim = 4\n\nbem_mri_images = \"FLASH\"\nrecreate_bem = True\n\nn_jobs = 2\n\n\ndef mri_t1_path_generator(bids_path):\n    # don't really do any modifications \u2013\u00a0just for testing!\n    return bids_path\n</code></pre>"},{"location":"examples/ds000248_base.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-01_task-audiovisual_report.html </p> <p>sub-average_task-audiovisual_report.html </p>"},{"location":"examples/ds000248_ica.html","title":"MNE Sample Data: ICA","text":""},{"location":"examples/ds000248_ica.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u274c Time-by-time decoding \u274c Time-generalization decoding \u274c CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/ds000248_ica.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds000248</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds000248 \\\n             --include=sub-01 \\\n             --include=sub-emptyroom \\\n             --include=derivatives/freesurfer/subjects \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2005s+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2009s+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/xhemi/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.a2009s+aseg.mgz\n</code></pre></p> <p>Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage.</p>"},{"location":"examples/ds000248_ica.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>study_name = 'MNE \"sample\" dataset'\nbids_root = \"~/mne_data/ds000248\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds000248_ica\"\n\nch_types = [\"meg\"]\ndata_type = \"meg\"\n\nsubjects = [\"01\"]\ntask = \"audiovisual\"\nl_freq = 0.3\nh_freq = 40.0\n\nconditions = [\"Auditory/Left\", \"Auditory/Right\", \"Visual/Left\", \"Visual/Right\"]\n\nepochs_tmin = -0.2\nepochs_tmax = 0.5\nbaseline = (None, 0)\nica_reject = dict(mag=3000e-15, grad=3000e-13)\n\nspatial_filter = \"ica\"\nica_algorithm = \"extended_infomax\"\nica_l_freq = 1.0\nica_n_components = 0.8\nica_max_iterations = 500\n\ninteractive = False\n</code></pre>"},{"location":"examples/ds000248_ica.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-01_task-audiovisual_report.html </p> <p>sub-average_task-audiovisual_report.html </p> Data cleaning <p>sub-01_task-audiovisual_proc-ica+components_report.html </p> <p>sub-01_task-audiovisual_proc-ica_report.html </p>"},{"location":"examples/ds000248_no_mri.html","title":"MNE Sample Data: Using the <code>fsaverage</code> template MRI","text":""},{"location":"examples/ds000248_no_mri.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-generalization decoding \u274c CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u2705"},{"location":"examples/ds000248_no_mri.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds000248</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds000248 \\\n             --include=sub-01 \\\n             --include=sub-emptyroom \\\n             --include=derivatives/freesurfer/subjects \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2005s+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2009s+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/fsaverage/xhemi/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/sub-01/mri/aparc.a2009s+aseg.mgz\n</code></pre></p> <p>Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage.</p>"},{"location":"examples/ds000248_no_mri.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>study_name = \"ds000248\"\nbids_root = \"~/mne_data/ds000248\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds000248_no_mri\"\nsubjects_dir = f\"{bids_root}/derivatives/freesurfer/subjects\"\n\nsubjects = [\"01\"]\nrename_events = {\"Smiley\": \"Emoji\", \"Button\": \"Switch\"}\nconditions = [\"Auditory\", \"Visual\", \"Auditory/Left\", \"Auditory/Right\"]\ncontrasts = [(\"Auditory/Right\", \"Auditory/Left\")]\n\nch_types = [\"meg\"]\nuse_maxwell_filter = False\nprocess_empty_room = False\n\nuse_template_mri = \"fsaverage\"\nadjust_coreg = True\n</code></pre>"},{"location":"examples/ds000248_no_mri.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-01_task-audiovisual_report.html </p> <p>sub-average_task-audiovisual_report.html </p>"},{"location":"examples/ds001810.html","title":"tDCS EEG","text":""},{"location":"examples/ds001810.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-generalization decoding \u274c CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/ds001810.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds001810</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds001810 \\\n             --include=sub-01\n</code></pre></p>"},{"location":"examples/ds001810.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>study_name = \"ds001810\"\nbids_root = \"~/mne_data/ds001810\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds001810\"\n\ntask = \"attentionalblink\"\ninteractive = False\nch_types = [\"eeg\"]\neeg_template_montage = \"biosemi64\"\nreject = dict(eeg=100e-6)\nbaseline = (None, 0)\nconditions = [\"61450\", \"61511\"]\ncontrasts = [(\"61450\", \"61511\")]\ndecode = True\ndecoding_n_splits = 3  # only for testing, use 5 otherwise\n\nl_freq = 0.3\n\nsubjects = [\"01\"]\nsessions = \"all\"\n\ninterpolate_bads_grand_average = False\nn_jobs = 4\n</code></pre>"},{"location":"examples/ds001810.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-01_ses-anodalpost_task-attentionalblink_report.html </p> <p>sub-01_ses-anodalpre_task-attentionalblink_report.html </p> <p>sub-01_ses-anodaltDCS_task-attentionalblink_report.html </p> <p>sub-01_ses-cathodalpost_task-attentionalblink_report.html </p> <p>sub-01_ses-cathodalpre_task-attentionalblink_report.html </p> <p>sub-01_ses-cathodaltDCS_task-attentionalblink_report.html </p> <p>sub-average_ses-anodalpost_task-attentionalblink_report.html </p> <p>sub-average_ses-anodalpre_task-attentionalblink_report.html </p> <p>sub-average_ses-anodaltDCS_task-attentionalblink_report.html </p> <p>sub-average_ses-cathodalpost_task-attentionalblink_report.html </p> <p>sub-average_ses-cathodalpre_task-attentionalblink_report.html </p> <p>sub-average_ses-cathodaltDCS_task-attentionalblink_report.html </p>"},{"location":"examples/ds001971.html","title":"Mobile brain body imaging (MoBI) gait adaptation experiment.","text":"<p>See ds001971 on OpenNeuro: https://github.com/OpenNeuroDatasets/ds001971</p>"},{"location":"examples/ds001971.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-generalization decoding \u2705 CSP decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/ds001971.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds001971</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds001971 \\\n             --include=sub-001/eeg/sub-001_task-AudioCueWalkingStudy_run-01_events.tsv \\\n             --include=sub-001/eeg/sub-001_task-AudioCueWalkingStudy_run-01_eeg.set \\\n             --include=sub-001/eeg/sub-001_task-AudioCueWalkingStudy_run-01_eeg.fdt \\\n             --include=sub-001/eeg/sub-001_task-AudioCueWalkingStudy_run-01_eeg.json \\\n             --include=sub-001/eeg/sub-001_task-AudioCueWalkingStudy_run-01_electrodes.tsv \\\n             --include=sub-001/eeg/sub-001_task-AudioCueWalkingStudy_run-01_coordsystem.json \\\n             --include=sub-001/eeg/sub-001_task-AudioCueWalkingStudy_run-01_channels.tsv\n</code></pre></p>"},{"location":"examples/ds001971.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>study_name = \"ds001971\"\nbids_root = \"~/mne_data/ds001971\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds001971\"\n\ntask = \"AudioCueWalkingStudy\"\ninteractive = False\nch_types = [\"eeg\"]\nreject = {\"eeg\": 150e-6}\nconditions = [\"AdvanceTempo\", \"DelayTempo\"]\ncontrasts = [(\"AdvanceTempo\", \"DelayTempo\")]\n\nsubjects = [\"001\"]\nruns = [\"01\"]\nepochs_decim = 5  # to 100 Hz\n\n# This is mostly for testing purposes!\ndecode = True\ndecoding_time_generalization = True\ndecoding_time_generalization_decim = 2\ndecoding_csp = True\ndecoding_csp_freqs = {\n    \"beta\": [13, 20, 30],\n}\ndecoding_csp_times = [-0.2, 0.0, 0.2, 0.4]\n\n# Just to test that MD5 works\nmemory_file_method = \"hash\"\n</code></pre>"},{"location":"examples/ds001971.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-001_task-AudioCueWalkingStudy_report.html </p> <p>sub-average_task-AudioCueWalkingStudy_report.html </p>"},{"location":"examples/ds003104.html","title":"Somato","text":""},{"location":"examples/ds003104.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u274c Time-by-time decoding \u274c Time-generalization decoding \u274c CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/ds003104.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds003104</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds003104 \\\n             --include=sub-01 \\\n             --include=derivatives/freesurfer/subjects \\\n             --exclude=derivatives/freesurfer/subjects/01/mri/aparc+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/01/mri/aparc.DKTatlas+aseg.mgz \\\n             --exclude=derivatives/freesurfer/subjects/01/mri/aparc.a2009s+aseg.mgz\n</code></pre></p> <p>Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage.</p>"},{"location":"examples/ds003104.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>study_name = \"MNE-somato-data-anonymized\"\nbids_root = \"~/mne_data/ds003104\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds003104\"\nsubjects_dir = f\"{bids_root}/derivatives/freesurfer/subjects\"\n\nconditions = [\"somato_event1\"]\nch_types = [\"meg\"]\n</code></pre>"},{"location":"examples/ds003104.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-01_task-somato_report.html </p> <p>sub-average_task-somato_report.html </p>"},{"location":"examples/ds003392.html","title":"hMT+ Localizer","text":""},{"location":"examples/ds003392.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-generalization decoding \u2705 CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/ds003392.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds003392</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds003392 \\\n             --include=sub-01 \\\n             --include=sub-emptyroom/ses-19111211\n</code></pre></p>"},{"location":"examples/ds003392.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>study_name = \"localizer\"\nbids_root = \"~/mne_data/ds003392\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds003392\"\n\nsubjects = [\"01\"]\n\ntask = \"localizer\"\nfind_flat_channels_meg = True\nfind_noisy_channels_meg = True\nuse_maxwell_filter = True\nch_types = [\"meg\"]\n\nl_freq = 1.0\nh_freq = 40.0\nraw_resample_sfreq = 250\ncrop_runs = (0, 180)\n\n# Artifact correction.\nspatial_filter = \"ica\"\nica_algorithm = \"picard-extended_infomax\"\nica_max_iterations = 500\nica_l_freq = 1.0\nica_n_components = 0.99\nica_reject_components = \"auto\"\n\n# Epochs\nepochs_tmin = -0.2\nepochs_tmax = 1.0\nbaseline = (None, 0)\n\n# Conditions / events to consider when epoching\nconditions = [\"coherent\", \"incoherent\"]\n\n# Decoding\ndecode = True\ndecoding_time_generalization = True\ndecoding_time_generalization_decim = 4\ncontrasts = [(\"incoherent\", \"coherent\")]\n\n# Noise estimation\nnoise_cov = \"emptyroom\"\n</code></pre>"},{"location":"examples/ds003392.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-01_task-localizer_report.html </p> <p>sub-average_task-localizer_report.html </p> Data cleaning <p>sub-01_task-localizer_proc-ica+components_report.html </p> <p>sub-01_task-localizer_proc-ica_report.html </p>"},{"location":"examples/ds003775.html","title":"SRM Resting-state EEG","text":""},{"location":"examples/ds003775.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u274c Time-by-time decoding \u274c Time-generalization decoding \u274c CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/ds003775.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds003775</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds003775 \\\n             --include=sub-010\n</code></pre></p>"},{"location":"examples/ds003775.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>study_name = \"ds003775\"\nbids_root = \"~/mne_data/ds003775\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds003775\"\n\n# To get all subjects for example:\n# from mne_bids import get_entity_vals\n# subjects = sorted(get_entity_vals(bids_root, entity_key='subject'))\nsubjects = [\"010\"]\n\nreader_extra_params = {\"units\": \"uV\"}\n\nsessions = [\"t1\"]\n\nrun_source_estimation = False\n\nch_types = [\"eeg\"]\n\nbaseline = None\nreject = None\nspatial_filter = None\n\nh_freq = 40\nl_freq = None\n\ntask = \"resteyesc\"\ntask_is_rest = True\nepochs_tmin = 0.0\nepochs_tmax = 10.0\nrest_epochs_overlap = 0.0\nrest_epochs_duration = 10.0\nbaseline = None\n\nparallel_backend = \"loky\"\ndask_open_dashboard = True\n\nlog_level = \"info\"\n\nn_jobs = 1\n</code></pre>"},{"location":"examples/ds003775.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-010_ses-t1_task-resteyesc_report.html </p>"},{"location":"examples/ds004107.html","title":"MIND DATA","text":"<p>M.P. Weisend, F.M. Hanlon, R. Monta\u00f1o, S.P. Ahlfors, A.C. Leuthold, D. Pantazis, J.C. Mosher, A.P. Georgopoulos, M.S. H\u00e4m\u00e4l\u00e4inen, C.J. Aine,, V. (2007). Paving the way for cross-site pooling of magnetoencephalography (MEG) data. International Congress Series, Volume 1300, Pages 615-618.</p>"},{"location":"examples/ds004107.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u2705 ICA \u274c Evoked contrasts \u274c Time-by-time decoding \u274c Time-generalization decoding \u274c CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/ds004107.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds004107</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds004107 \\\n             --include=sub-mind002/ses-01/meg/*coordsystem* \\\n             --include=sub-mind002/ses-01/meg/*auditory*\n</code></pre></p>"},{"location":"examples/ds004107.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code># This has auditory, median, indx, visual, rest, and emptyroom but let's just\n# process the auditory (it's the smallest after rest)\nstudy_name = \"ds004107\"\nbids_root = f\"~/mne_data/{study_name}\"\nderiv_root = f\"~/mne_data/derivatives/mne-bids-pipeline/{study_name}\"\nsubjects = [\"mind002\"]\nsessions = [\"01\"]\nconditions = [\"left\", \"right\"]  # there are also tone and noise\ntask = \"auditory\"\nch_types = [\"meg\"]\ncrop_runs = (0, 120)  # to speed up computations\nspatial_filter = \"ssp\"\nl_freq = 1.0\nh_freq = 40.0\n</code></pre>"},{"location":"examples/ds004107.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-average_ses-01_task-auditory_report.html </p> <p>sub-mind002_ses-01_task-auditory_report.html </p>"},{"location":"examples/ds004229.html","title":"Single-subject infant dataset for testing maxwell_filter with movecomp.","text":"<p>https://openneuro.org/datasets/ds004229</p>"},{"location":"examples/ds004229.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u2705 ICA \u274c Evoked contrasts \u274c Time-by-time decoding \u274c Time-generalization decoding \u274c CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/ds004229.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://openneuro.org/datasets/ds004229</p> How to download this dataset <p>Run in your terminal: Run in your terminal<pre><code>openneuro-py download \\\n             --dataset=ds004229 \\\n             --include=sub-102 \\\n             --include=sub-emptyroom/ses-20000101\n</code></pre></p>"},{"location":"examples/ds004229.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>import mne\nimport numpy as np\n\nstudy_name = \"amnoise\"\nbids_root = \"~/mne_data/ds004229\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/ds004229\"\n\ntask = \"amnoise\"\ncrop_runs = (300.0, 600.0)  # 5 minutes from the middle of the recording for speed\n\nfind_flat_channels_meg = True\nfind_noisy_channels_meg = True\nuse_maxwell_filter = True\nmf_destination = mne.transforms.translation(  # rotate backward and move up\n    z=0.055,\n) @ mne.transforms.rotation(x=np.deg2rad(-15))\nmf_mc = True\nmf_st_duration = 10\nmf_int_order = 6  # lower for smaller heads\nmf_mc_t_step_min = 0.5  # just for speed!\nmf_mc_t_window = 0.2  # cleaner cHPI filtering on this dataset\nmf_filter_chpi = False  # for speed, not needed as we low-pass anyway\nmf_mc_rotation_velocity_limit = 30.0  # deg/s for annotations\nmf_mc_translation_velocity_limit = 20e-3  # m/s\nmf_esss = 8\nmf_esss_reject = {\"grad\": 10000e-13, \"mag\": 40000e-15}\nch_types = [\"meg\"]\n\nl_freq = None\nh_freq = 40.0\n\n# SSP and peak-to-peak rejection\nspatial_filter = \"ssp\"\nn_proj_eog = dict(n_mag=0, n_grad=0)\nn_proj_ecg = dict(n_mag=2, n_grad=2)\nssp_ecg_channel = \"MEG0113\"  # ECG channel is not hooked up in this dataset\nreject = ssp_reject_ecg = {\"grad\": 2000e-13, \"mag\": 5000e-15}\n\n# Epochs\nepochs_tmin = -0.2\nepochs_tmax = 1\nepochs_decim = 6  # 1200-&gt;200 Hz\nbaseline = (None, 0)\n\n# Conditions / events to consider when epoching\nconditions = [\"auditory\"]\n\n# Decoding\ndecode = False\n\n# Noise estimation\nnoise_cov = \"emptyroom\"\n</code></pre>"},{"location":"examples/ds004229.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-102_task-amnoise_report.html </p> <p>sub-average_task-amnoise_report.html </p>"},{"location":"examples/eeg_matchingpennies.html","title":"Matchingpennies EEG experiment","text":""},{"location":"examples/eeg_matchingpennies.html#demonstrated-features","title":"Demonstrated features","text":"Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-generalization decoding \u274c CSP decoding \u274c Time-frequency analysis \u274c BEM surface creation \u274c Template MRI \u274c"},{"location":"examples/eeg_matchingpennies.html#dataset-source","title":"Dataset source","text":"<p>This dataset was acquired from https://osf.io/download/8rbfk?version=1</p>"},{"location":"examples/eeg_matchingpennies.html#configuration","title":"Configuration","text":"Click to expand Python<pre><code>study_name = \"eeg_matchingpennies\"\nbids_root = \"~/mne_data/eeg_matchingpennies\"\nderiv_root = \"~/mne_data/derivatives/mne-bids-pipeline/eeg_matchingpennies\"\n\nsubjects = [\"05\"]\ntask = \"matchingpennies\"\nch_types = [\"eeg\"]\ninteractive = False\nreject = {\"eeg\": 150e-6}\nconditions = [\"raised-left\", \"raised-right\"]\ncontrasts = [(\"raised-left\", \"raised-right\")]\ndecode = True\n\ninterpolate_bads_grand_average = False\n</code></pre>"},{"location":"examples/eeg_matchingpennies.html#generated-output","title":"Generated output","text":"Summary reports <p>sub-05_task-matchingpennies_report.html </p> <p>sub-average_task-matchingpennies_report.html </p>"},{"location":"examples/examples.html","title":"Examples","text":"<p>Here you will find a number of examples using publicly available datasets, mostly taken from OpenNeuro.</p> <p>For a first example, see the results obtained with the MNE sample dataset.</p>"},{"location":"examples/examples.html#demonstrated-features","title":"Demonstrated features","text":"Dataset MEG processing EEG processing Maxwell filter Frequency filter SSP ICA Evoked contrasts Time-by-time decoding Time-generalization decoding CSP decoding Time-frequency analysis BEM surface creation Template MRI ds003392 \u2705 \u274c \u2705 \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u274c \u274c \u274c \u274c ds004229 \u2705 \u274c \u2705 \u2705 \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c ds001971 \u274c \u2705 \u274c \u2705 \u274c \u274c \u2705 \u2705 \u2705 \u2705 \u274c \u274c \u274c ds004107 \u2705 \u274c \u274c \u2705 \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c ds000117 \u2705 \u274c \u2705 \u2705 \u274c \u274c \u2705 \u2705 \u2705 \u274c \u274c \u274c \u274c ds003775 \u274c \u2705 \u274c \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c eeg_matchingpennies \u274c \u2705 \u274c \u2705 \u274c \u274c \u2705 \u2705 \u274c \u274c \u274c \u274c \u274c ds000246 \u2705 \u274c \u274c \u2705 \u274c \u274c \u2705 \u2705 \u2705 \u274c \u274c \u274c \u274c ds000247 \u2705 \u274c \u274c \u2705 \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u274c ds000248_base \u2705 \u2705 \u2705 \u2705 \u2705 \u274c \u2705 \u2705 \u274c \u274c \u2705 \u2705 \u274c ds000248_ica \u2705 \u274c \u274c \u2705 \u274c \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c ds000248_T1_BEM \u2705 \u274c \u274c \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u2705 \u274c ds000248_FLASH_BEM \u2705 \u274c \u274c \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u2705 \u274c ds000248_no_mri \u2705 \u274c \u274c \u2705 \u274c \u274c \u2705 \u2705 \u274c \u274c \u274c \u274c \u2705 ds001810 \u274c \u2705 \u274c \u2705 \u274c \u274c \u2705 \u2705 \u274c \u274c \u274c \u274c \u274c ds003104 \u2705 \u274c \u274c \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c ERP_CORE \u274c \u2705 \u274c \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u2705 \u274c \u274c \u274c"},{"location":"features/overview.html","title":"Overview","text":"<p>MNE-BIDS-Pipeline processes your data in a sequential manner, i.e., one step at a time. The next step is only run after the previous steps have been successfully completed. There are, of course, exceptions; for example, if you chose not to apply ICA, the respective steps will simply be omitted and we'll directly move to the subsequent steps. The following flow chart aims to give you a brief overview of which steps are included in the pipeline, in which order they are run, and how we group them together.</p> <p>Info</p> <p>All intermediate results are saved to disk for later inspection, and an extensive report is generated.</p> <p>Info</p> <p>Analyses are conducted on individual (per-subject) as well as group level.</p>"},{"location":"features/overview.html#filesystem-initialization-and-dataset-inspection","title":"Filesystem initialization and dataset inspection","text":"<pre><code>flowchart TD\n    A1[initialize the target directories] --&gt; A2[locate empty-room recordings]</code></pre>"},{"location":"features/overview.html#preprocessing","title":"Preprocessing","text":"<pre><code>    flowchart TD\n    B1[Noisy &amp; flat channel detection] --&gt; B2[Maxwell filter]\n    B2 --&gt; B3[Frequency filter]\n    B3 --&gt; B4[Epoch creation]\n    B4 --&gt; B5[SSP or ICA fitting]\n    B5 --&gt; B6[Artifact removal via SSP or ICA]\n    B6 --&gt; B7[Amplitude-based epoch rejection]</code></pre>"},{"location":"features/overview.html#sensor-space-processing","title":"Sensor-space processing","text":"<pre><code>    flowchart TD\n    C1[ERP / ERF calculation] --&gt; C2[MVPA: full epochs]\n    C2 --&gt; C3[MVPA: time-by-time decoding]\n    C3 --&gt; C4[Time-frequency decomposition]\n    C4 --&gt; C5[MVPA: CSP]\n    C5 --&gt; C6[Noise covariance estimation]\n    C6 --&gt; C7[Grand average]</code></pre>"},{"location":"features/overview.html#source-space-processing","title":"Source-space processing","text":"<pre><code>    flowchart TD\n    D1[BEM surface creation] --&gt; D2[BEM solution]\n    D2 --&gt; D3[Source space creation]\n    D3 --&gt; D4[Forward model creation]\n    D4 --&gt; D5[Inverse solution]\n    D5 --&gt; D6[Grand average]</code></pre>"},{"location":"features/steps.html","title":"Detailed lis of processing steps","text":"<p>The following table provides a concise summary of each processing step. The step names can be used to run individual steps or entire groups of steps by passing their name(s) to <code>mne_bids_pipeline</code> via the <code>steps=...</code> argument.</p>"},{"location":"features/steps.html#1-filesystem-initialization-and-dataset-inspection","title":"1. Filesystem initialization and dataset inspection","text":"Step name Description <code>init</code> Run all filesystem initialization and dataset inspection steps. <code>init/_01_init_derivatives_dir</code> Initialize derivatives_dir. <code>init/_02_find_empty_room</code> Find empty-room data matches."},{"location":"features/steps.html#2-preprocessing","title":"2. Preprocessing","text":"Step name Description <code>preprocessing</code> Run all preprocessing steps. <code>preprocessing/_01_data_quality</code> Assess data quality and find bad (and flat) channels. <code>preprocessing/_02_head_pos</code> Estimate head positions. <code>preprocessing/_03_maxfilter</code> Maxwell-filter MEG data. <code>preprocessing/_04_frequency_filter</code> Apply low- and high-pass filters. <code>preprocessing/_05_make_epochs</code> Extract epochs. <code>preprocessing/_06a_run_ica</code> Run Independent Component Analysis (ICA) for artifact correction. <code>preprocessing/_06b_run_ssp</code> Run Signal Subspace Projections (SSP) for artifact correction. <code>preprocessing/_07a_apply_ica</code> Apply ICA and obtain the cleaned epochs. <code>preprocessing/_07b_apply_ssp</code> Apply SSP projections and obtain the cleaned epochs. <code>preprocessing/_08_ptp_reject</code> Remove epochs based on peak-to-peak (PTP) amplitudes."},{"location":"features/steps.html#3-sensor-space-analysis","title":"3. Sensor-space analysis","text":"Step name Description <code>sensor</code> Run all sensor-space analysis steps. <code>sensor/_01_make_evoked</code> Extract evoked data for each condition. <code>sensor/_02_decoding_full_epochs</code> Decode pairs of conditions based on entire epochs. <code>sensor/_03_decoding_time_by_time</code> Decode time-by-time using a \"sliding\" estimator. <code>sensor/_04_time_frequency</code> Time-frequency decomposition. <code>sensor/_05_decoding_csp</code> <code>sensor/_06_make_cov</code> Noise covariance estimation. <code>sensor/_99_group_average</code> Group average at the sensor level."},{"location":"features/steps.html#4-source-space-analysis","title":"4. Source-space analysis","text":"Step name Description <code>source</code> Run all source-space analysis steps. <code>source/_01_make_bem_surfaces</code> Create BEM surfaces. <code>source/_02_make_bem_solution</code> Compute BEM solution. <code>source/_03_setup_source_space</code> Setup source space. <code>source/_04_make_forward</code> Forward solution. <code>source/_05_make_inverse</code> Inverse solution. <code>source/_99_group_average</code> Group average at the source level."},{"location":"features/steps.html#5-freesurfer-related-processing","title":"5. FreeSurfer-related processing","text":"<p>Surface reconstruction via FreeSurfer. These steps are not run by default.</p> Step name Description <code>freesurfer</code> Run all freesurfer-related processing steps. <code>freesurfer/_01_recon_all</code> Run FreeSurfer's recon-all. <code>freesurfer/_02_coreg_surfaces</code> Generate coregistration surfaces."},{"location":"getting_started/basic_usage.html","title":"Basic usage","text":""},{"location":"getting_started/basic_usage.html#prepare-your-dataset","title":"Prepare your dataset","text":"<p>MNE-BIDS-Pipeline only works with BIDS-formatted raw data. To find out more about BIDS and how to convert your data to the BIDS format, please see the documentation of MNE-BIDS.</p> <p>We recommend that</p> <ul> <li> <p>faulty channels are marked as \"bad\".</p> Why? <p>While we do run automated bad channel detection in the pipeline, it is considered good practice to flag obviously problematic channels as such in the BIDS dataset.</p> How? <p>MNE-BIDS provides a convenient way to visually inspect raw data and interactively mark problematic channels as bad by using the command Run in your terminal<pre><code>mne-bids inspect\n</code></pre> Please see the MNE-BIDS documentation for more information.</p> </li> <li> <p>the data is anonymized before running the pipeline if you   require anonymization, as the pipeline itself does not allow for anonymization.</p> Why? <p>This was a conscious design decision, not a technical limitation per se. If you think this decision should be reconsidered, please get in touch with the developers.</p> How? <p>If you already have BIDS formatted data you can use <code>mne_bids.anonymize_dataset</code>. Otherwise you can use the <code>mne_bids.write_raw_bids</code> function of MNE-BIDS that accepts an <code>anonymize</code> parameter and can be used to anonymize your data by removing subject-identifying information and shifting the measurement date by a given number of days. For example, you could use Python<pre><code>from mne_bids import write_raw_bids\n\nwrite_raw_bids(..., anonymize=dict(daysback=1000))\n</code></pre> to shift the recording date 1000 days into the past. By default, information like participant handedness etc. will be removed as well.</p> <p>You can also deface your MRIs with <code>mne_bids.write_anat</code>: Python<pre><code>from mne_bids import write_anat\n\nwrite_anat(..., landmarks=landmarks, deface=True)\n</code></pre> Please see the tutorials of <code>mne_bids</code> for more information.</p> </li> </ul>"},{"location":"getting_started/basic_usage.html#create-a-configuration-file","title":"Create a configuration file","text":"<p>All parameters of the pipeline are controlled via a configuration file. You can create a template configuration file by running the following command:</p> Create a template configuration file Run in your terminal<pre><code>mne_bids_pipeline --create-config=/path/to/your/custom_config.py\n</code></pre> <p>You can then edit the file and adjust all parameters that are relevant to your data processing and analysis.</p>"},{"location":"getting_started/basic_usage.html#run-the-pipeline","title":"Run the pipeline","text":"Run the full pipeline <p>To run the full pipeline, execute the following command in your terminal: Run in your terminal<pre><code>mne_bids_pipeline --config=/path/to/your/custom_config.py\n</code></pre></p> Run only parts of the pipeline <p>Run only the preprocessing steps: Run in your terminal<pre><code>mne_bids_pipeline --config=/path/to/your/custom_config.py --steps=preprocessing\n</code></pre></p> <p>Run only the sensor-level processing steps: Run in your terminal<pre><code>mne_bids_pipeline --config=/path/to/your/custom_config.py --steps=sensor\n</code></pre></p> <p>Run only the source-level (inverse solution) processing steps: Run in your terminal<pre><code>mne_bids_pipeline --config=/path/to/your/custom_config.py --steps=source\n</code></pre></p> <p>(Re-)run ICA: Run in your terminal<pre><code>mne_bids_pipeline --config=/path/to/your/custom_config.py --steps=preprocessing/ica\n</code></pre></p> <p>You can also run multiple steps with one command by separating different steps by a comma. For example, to run preprocessing and sensor-level processing steps using a single command, do: Run in your terminal<pre><code>mne_bids_pipeline --config=/path/to/your/custom_config.py --steps=preprocessing,sensor\n</code></pre></p> <p>You can directly visit our examples page to see some configuration files and the corresponding results.</p>"},{"location":"getting_started/freesurfer.html","title":"Preparations for source-level analyses","text":"<p>Info</p> <p>Preparations for inverse modeling involve the installation of FreeSurfer. If you do not intend to run the source reconstruction steps of MNE-BIDS-Pipeline, you can skip the instructions below.</p> <p>Warning</p> <p>FreeSurfer does not natively run on Windows. We are currently working on ways to make it possible to use it on Windows, too.</p>"},{"location":"getting_started/freesurfer.html#prerequisites","title":"Prerequisites","text":"<p>To perform inverse modeling, or also called source estimation or source localization, we need to ensure that a couple prerequisites are met. Essentially, starting from a collection of 2-dimensional MRI images of coronal, axial, and sagittal slices of a participant's head, we need to construct a 3-dimensional representation of the brain, skull, and scalp. Furthermore, it's highly advantegous to attach labels to different brain areas according to common anatomical atlases, so that we could, for example, restrict subsequent analyses to specific cortical regions, and compare activation in these regions across participants.</p> <p>BIDS raw datasets, however, do not include any of these 3D representations and parcellations. (Note that, however, these derivatives are sometimes distributed along with a datasets inside a <code>derivatives/</code> folder). Instead, they ship e.g. with T1-weighted images only (and, sometimes, include FLASH images too).</p>"},{"location":"getting_started/freesurfer.html#install-freesurfer","title":"Install FreeSurfer","text":"<p>Before running the source-analysis parts of the pipeline, you need to create the above-mentioned 3D surfaces and parcellations. This is done using the FreeSurfer tool. FreeSurfer is a free software package that runs on macOS and Linux.</p> <p>To install FreeSurfer, follow the official download and installation nstructions.</p> <p>Info</p> <p>The only currently tested FreeSurfer version is 6.0.</p>"},{"location":"getting_started/freesurfer.html#generate-surfaces-and-brain-parcellation","title":"Generate surfaces and brain parcellation","text":"<p>MNE-BIDS-Pipeline provides a convenient way to invoke FreeSurfer. After adjusting your configuration file, invoke FreeSurfer via in the following way:</p> Run in your terminal<pre><code>mne_bids_pipeline --steps=freesurfer --config=/path/to/your/custom_config.py\n</code></pre> <p>This will run the <code>recon-all</code> command to create the required surfaces.</p> <p>Info</p> <p>This process is very computationally expensive, and will usually take several hours to complete. It's a good idea to let this command run over night.</p>"},{"location":"getting_started/freesurfer.html#run-source-level-analyses","title":"Run source-level analyses","text":"<p>Now you are ready to run MNE-BIDS-Pipeline, including all parts of inverse modeling. To perform the projection, MNE-Python will first need to detect brain, skull, and skin, so it can then start constructing the actual BEM conductor model. These BEM surfaces can be created based on FLASH MRI (best option) or T1-weighted MRI images (second-best). See the respective configuration options to control BEM surface creation.</p>"},{"location":"getting_started/install.html","title":"Installation","text":""},{"location":"getting_started/install.html#installing-mne-bids-pipeline-and-all-dependencies","title":"Installing MNE-BIDS-Pipeline and all dependencies","text":"<p>There are a few different ways to install MNE-BIDS-Pipeline, depending on how you installed MNE-Python.</p> MNE installerconda (new environment)conda (existing environment)pip <p> Nothing to do! If you used the MNE-Python installer for version 1.3 or later, MNE-BIDS-Pipeline is already installed!</p> <p> We strongly advise you to install MNE-BIDS-Pipeline into a dedicated environment.</p> <p> Running the following commands will first install <code>mamba</code>, an extremely fast drop-in replacement for <code>conda</code>, and then proceed to create an environment named <code>mne</code> with MNE-BIDS-Pipeline and all required dependencies: Run in your terminal<pre><code>conda install --channel=conda-forge mamba\nmamba create --override-channels --channel=conda-forge --name=mne mne-bids-pipeline\n</code></pre></p> <p> If you already have a <code>conda</code> environment with MNE-Python installed following the official installation instructions, you can install the pipeline into the existing environment. We recommend using <code>mamba</code>, an extremely fast drop-in replacement for <code>conda</code>: Run in your terminal<pre><code>conda install --channel=conda-forge mamba\nmamba install --override-channels --channel=conda-forge --name=mne mne-bids-pipeline\n</code></pre></p> <p> Activate your Python environment and run: Run in your terminal<pre><code>pip install --upgrade mne-bids-pipeline\n</code></pre></p>"},{"location":"getting_started/install.html#testing-the-installation","title":"Testing the installation","text":"<p>If the installation was successful, the command-line utility <code>mne_bids_pipeline</code> (mind the underscores!) should now be available in your Python environment.</p> <p>Info</p> <p><code>mne_bids_pipeline</code> will be used to operate the pipeline.</p> <p>To check whether the command exists, and to verify which version of MNE-BIDS-Pipeline is currently installed, run:</p> Run in your terminal<pre><code>mne_bids_pipeline --version\n</code></pre> <p>That's it! </p> <p>You're now ready to start using MNE-BIDS-Pipeline.</p>"},{"location":"settings/general.html","title":"General settings","text":""},{"location":"settings/general.html#mne_bids_pipeline._config.study_name","title":"study_name  <code>module-attribute</code>","text":"Python<pre><code>study_name = ''\n</code></pre> <p>Specify the name of your study. It will be used to populate filenames for saving the analysis results.</p> Example Python<pre><code>study_name = 'my-study'\n</code></pre>"},{"location":"settings/general.html#mne_bids_pipeline._config.bids_root","title":"bids_root  <code>module-attribute</code>","text":"Python<pre><code>bids_root = None\n</code></pre> <p>Specify the BIDS root directory. Pass an empty string or <code>``None</code> to use the value specified in the <code>BIDS_ROOT</code> environment variable instead. Raises an exception if the BIDS root has not been specified.</p> Example Python<pre><code>bids_root = '/path/to/your/bids_root'  # Use this to specify a path here.\nbids_root = None  # Make use of the `BIDS_ROOT` environment variable.\n</code></pre>"},{"location":"settings/general.html#mne_bids_pipeline._config.deriv_root","title":"deriv_root  <code>module-attribute</code>","text":"Python<pre><code>deriv_root = None\n</code></pre> <p>The root of the derivatives directory in which the pipeline will store the processing results. If <code>None</code>, this will be <code>derivatives/mne-bids-pipeline</code> inside the BIDS root.</p> <p>Info</p> <p>If specified and you wish to run the source analysis steps, you must set <code>subjects_dir</code> as well.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.subjects_dir","title":"subjects_dir  <code>module-attribute</code>","text":"Python<pre><code>subjects_dir = None\n</code></pre> <p>Path to the directory that contains the FreeSurfer reconstructions of all subjects. Specifically, this defines the <code>SUBJECTS_DIR</code> that is used by FreeSurfer.</p> <ul> <li>When running the <code>freesurfer</code> processing step to create the   reconstructions from anatomical scans in the BIDS dataset, the   output will be stored in this directory.</li> <li>When running the source analysis steps, we will look for the surfaces in this   directory and also store the BEM surfaces there.</li> </ul> <p>If <code>None</code>, this will default to <code>bids_root</code><code>/derivatives/freesurfer/subjects</code>.</p> <p>Info</p> <p>This setting is required if you specify <code>deriv_root</code> and want to run the source analysis steps.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.interactive","title":"interactive  <code>module-attribute</code>","text":"Python<pre><code>interactive = False\n</code></pre> <p>If True, the steps will provide some interactive elements, such as figures. If running the steps from a notebook or Spyder, run <code>%matplotlib qt</code> in the command line to open the figures in a separate window.</p> <p>Info</p> <p>Enabling interactive mode deactivates parallel processing.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.sessions","title":"sessions  <code>module-attribute</code>","text":"Python<pre><code>sessions = 'all'\n</code></pre> <p>The sessions to process. If <code>'all'</code>, will process all sessions found in the BIDS dataset.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.task","title":"task  <code>module-attribute</code>","text":"Python<pre><code>task = ''\n</code></pre> <p>The task to process.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.task_is_rest","title":"task_is_rest  <code>module-attribute</code>","text":"Python<pre><code>task_is_rest = False\n</code></pre> <p>Whether the task should be treated as resting-state data.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.runs","title":"runs  <code>module-attribute</code>","text":"Python<pre><code>runs = 'all'\n</code></pre> <p>The runs to process. If <code>'all'</code>, will process all runs found in the BIDS dataset.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.exclude_runs","title":"exclude_runs  <code>module-attribute</code>","text":"Python<pre><code>exclude_runs = None\n</code></pre> <p>Specify runs to exclude from analysis, for each participant individually.</p> Example Python<pre><code>exclude_runs = None  # Include all runs.\nexclude_runs = {'01': ['02']}  # Exclude run 02 of subject 01.\n</code></pre> Good Practice / Advice <p>Keep track of the criteria leading you to exclude a run (e.g. too many movements, missing blocks, aborted experiment, did not understand the instructions, etc.).</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.crop_runs","title":"crop_runs  <code>module-attribute</code>","text":"Python<pre><code>crop_runs = None\n</code></pre> <p>Crop the raw data of each run to the specified time interval <code>[tmin, tmax]</code>, in seconds. The runs will be cropped before Maxwell or frequency filtering is applied. If <code>None</code>, do not crop the data.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.acq","title":"acq  <code>module-attribute</code>","text":"Python<pre><code>acq = None\n</code></pre> <p>The BIDS <code>acquisition</code> entity.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.proc","title":"proc  <code>module-attribute</code>","text":"Python<pre><code>proc = None\n</code></pre> <p>The BIDS <code>processing</code> entity.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.rec","title":"rec  <code>module-attribute</code>","text":"Python<pre><code>rec = None\n</code></pre> <p>The BIDS <code>recording</code> entity.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.space","title":"space  <code>module-attribute</code>","text":"Python<pre><code>space = None\n</code></pre> <p>The BIDS <code>space</code> entity.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.subjects","title":"subjects  <code>module-attribute</code>","text":"Python<pre><code>subjects = 'all'\n</code></pre> <p>Subjects to analyze. If <code>'all'</code>, include all subjects. To only include a subset of subjects, pass a list of their identifiers. Even if you plan on analyzing only a single subject, pass their identifier as a list.</p> <p>Please note that if you intend to EXCLUDE only a few subjects, you should consider setting <code>subjects = 'all'</code> and adding the identifiers of the excluded subjects to <code>exclude_subjects</code> (see next section).</p> Example Python<pre><code>subjects = 'all'  # Include all subjects.\nsubjects = ['05']  # Only include subject 05.\nsubjects = ['01', '02']  # Only include subjects 01 and 02.\n</code></pre>"},{"location":"settings/general.html#mne_bids_pipeline._config.exclude_subjects","title":"exclude_subjects  <code>module-attribute</code>","text":"Python<pre><code>exclude_subjects = []\n</code></pre> <p>Specify subjects to exclude from analysis. The MEG empty-room mock-subject is automatically excluded from regular analysis.</p> Good Practice / Advice <p>Keep track of the criteria leading you to exclude a participant (e.g. too many movements, missing blocks, aborted experiment, did not understand the instructions, etc, ...) The <code>emptyroom</code> subject will be excluded automatically.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.process_empty_room","title":"process_empty_room  <code>module-attribute</code>","text":"Python<pre><code>process_empty_room = True\n</code></pre> <p>Whether to apply the same pre-processing steps to the empty-room data as to the experimental data (up until including frequency filtering). This is required if you wish to use the empty-room recording to estimate noise covariance (via <code>noise_cov='emptyroom'</code>). The empty-room recording corresponding to the processed experimental data will be retrieved automatically.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.process_rest","title":"process_rest  <code>module-attribute</code>","text":"Python<pre><code>process_rest = True\n</code></pre> <p>Whether to apply the same pre-processing steps to the resting-state data as to the experimental data (up until including frequency filtering). This is required if you wish to use the resting-state recording to estimate noise covariance (via <code>noise_cov='rest'</code>).</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.ch_types","title":"ch_types  <code>module-attribute</code>","text":"Python<pre><code>ch_types = []\n</code></pre> <p>The channel types to consider.</p> Example Python<pre><code># Use EEG channels:\nch_types = ['eeg']\n\n# Use magnetometer and gradiometer MEG channels:\nch_types = ['mag', 'grad']\n\n# Use MEG and EEG channels:\nch_types = ['meg', 'eeg']\n</code></pre>"},{"location":"settings/general.html#mne_bids_pipeline._config.data_type","title":"data_type  <code>module-attribute</code>","text":"Python<pre><code>data_type = None\n</code></pre> <p>The BIDS data type.</p> <p>For MEG recordings, this will usually be 'meg'; and for EEG, 'eeg'. However, if your dataset contains simultaneous recordings of MEG and EEG, stored in a single file, you will typically need to set this to 'meg'. If <code>None</code>, we will assume that the data type matches the channel type.</p> Example <p>The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the EEG data, which is stored inside the MEG files:</p> Python<pre><code>ch_types = ['eeg']\ndata_type = 'meg'\n</code></pre> <p>The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the gradiometer data:</p> Python<pre><code>ch_types = ['grad']\ndata_type = 'meg'  # or data_type = None\n</code></pre> <p>The dataset contains only EEG data:</p> Python<pre><code>ch_types = ['eeg']\ndata_type = 'eeg'  # or data_type = None\n</code></pre>"},{"location":"settings/general.html#mne_bids_pipeline._config.eog_channels","title":"eog_channels  <code>module-attribute</code>","text":"Python<pre><code>eog_channels = None\n</code></pre> <p>Specify EOG channels to use, or create virtual EOG channels.</p> <p>Allows the specification of custom channel names that shall be used as (virtual) EOG channels. For example, say you recorded EEG without dedicated EOG electrodes, but with some EEG electrodes placed close to the eyes, e.g. Fp1 and Fp2. These channels can be expected to have captured large quantities of ocular activity, and you might want to use them as \"virtual\" EOG channels, while also including them in the EEG analysis. By default, MNE won't know that these channels are suitable for recovering EOG, and hence won't be able to perform tasks like automated blink removal, unless a \"true\" EOG sensor is present in the data as well. Specifying channel names here allows MNE to find the respective EOG signals based on these channels.</p> <p>You can specify one or multiple channel names. Each will be treated as if it were a dedicated EOG channel, without excluding it from any other analyses.</p> <p>If <code>None</code>, only actual EOG channels will be used for EOG recovery.</p> <p>If there are multiple actual EOG channels in your data, and you only specify a subset of them here, only this subset will be used during processing.</p> Example <p>Treat <code>Fp1</code> as virtual EOG channel: Python<pre><code>eog_channels = ['Fp1']\n</code></pre></p> <p>Treat <code>Fp1</code> and <code>Fp2</code> as virtual EOG channels: Python<pre><code>eog_channels = ['Fp1', 'Fp2']\n</code></pre></p>"},{"location":"settings/general.html#mne_bids_pipeline._config.eeg_bipolar_channels","title":"eeg_bipolar_channels  <code>module-attribute</code>","text":"Python<pre><code>eeg_bipolar_channels = None\n</code></pre> <p>Combine two channels into a bipolar channel, whose signal is the difference between the two combined channels, and add it to the data. A typical use case is the combination of two EOG channels \u2013 for example, a left and a right horizontal EOG \u2013 into a single, bipolar EOG channel. You need to pass a dictionary whose keys are the name of the new bipolar channel you wish to create, and whose values are tuples consisting of two strings: the name of the channel acting as anode and the name of the channel acting as cathode, i.e. <code>{'ch_name': ('anode', 'cathode')}</code>. You can request to construct more than one bipolar channel by specifying multiple key/value pairs. See the examples below.</p> <p>Can also be <code>None</code> if you do not want to create bipolar channels.</p> <p>Info</p> <p>The channels used to create the bipolar channels are not automatically dropped from the data. To drop channels, set <code>drop_channels</code>.</p> Example <p>Combine the existing channels <code>HEOG_left</code> and <code>HEOG_right</code> into a new, bipolar channel, <code>HEOG</code>: Python<pre><code>eeg_add_bipolar_channels = {'HEOG': ('HEOG_left', 'HEOG_right')}\n</code></pre></p> <p>Create two bipolar channels, <code>HEOG</code> and <code>VEOG</code>: Python<pre><code>eeg_add_bipolar_channels = {'HEOG': ('HEOG_left', 'HEOG_right'),\n                            'VEOG': ('VEOG_lower', 'VEOG_upper')}\n</code></pre></p>"},{"location":"settings/general.html#mne_bids_pipeline._config.eeg_reference","title":"eeg_reference  <code>module-attribute</code>","text":"Python<pre><code>eeg_reference = 'average'\n</code></pre> <p>The EEG reference to use. If <code>average</code>, will use the average reference, i.e. the average across all channels. If a string, must be the name of a single channel. To use multiple channels as reference, set to a list of channel names.</p> Example <p>Use the average reference: Python<pre><code>eeg_reference = 'average'\n</code></pre></p> <p>Use the <code>P9</code> channel as reference: Python<pre><code>eeg_reference = 'P9'\n</code></pre></p> <p>Use the average of the <code>P9</code> and <code>P10</code> channels as reference: Python<pre><code>eeg_reference = ['P9', 'P10']\n</code></pre></p>"},{"location":"settings/general.html#mne_bids_pipeline._config.eeg_template_montage","title":"eeg_template_montage  <code>module-attribute</code>","text":"Python<pre><code>eeg_template_montage = None\n</code></pre> <p>In situations where you wish to process EEG data and no individual digitization points (measured channel locations) are available, you can apply a \"template\" montage. This means we will assume the EEG cap was placed either according to an international system like 10/20, or as suggested by the cap manufacturers in their respective manual.</p> <p>Please be aware that the actual cap placement most likely deviated somewhat from the template, and, therefore, source reconstruction may be impaired.</p> <p>If <code>None</code>, do not apply a template montage. If a string, must be the name of a built-in template montage in MNE-Python. You can find an overview of supported template montages at https://mne.tools/stable/generated/mne.channels.make_standard_montage.html</p> Example <p>Do not apply template montage: Python<pre><code>eeg_template_montage = None\n</code></pre></p> <p>Apply 64-channel Biosemi 10/20 template montage: Python<pre><code>eeg_template_montage = 'biosemi64'\n</code></pre></p>"},{"location":"settings/general.html#mne_bids_pipeline._config.drop_channels","title":"drop_channels  <code>module-attribute</code>","text":"Python<pre><code>drop_channels = []\n</code></pre> <p>Names of channels to remove from the data. This can be useful, for example, if you have added a new bipolar channel via <code>eeg_bipolar_channels</code> and now wish to remove the anode, cathode, or both.</p> Example <p>Exclude channels <code>Fp1</code> and <code>Cz</code> from processing: Python<pre><code>drop_channels = ['Fp1', 'Cz]\n</code></pre></p>"},{"location":"settings/general.html#mne_bids_pipeline._config.reader_extra_params","title":"reader_extra_params  <code>module-attribute</code>","text":"Python<pre><code>reader_extra_params = {}\n</code></pre> <p>Parameters to be passed to <code>read_raw_bids()</code> calls when importing raw data.</p> Example <p>Enforce units for EDF files: Python<pre><code>reader_extra_params = {\"units\": \"uV\"}\n</code></pre></p>"},{"location":"settings/general.html#mne_bids_pipeline._config.read_raw_bids_verbose","title":"read_raw_bids_verbose  <code>module-attribute</code>","text":"Python<pre><code>read_raw_bids_verbose = None\n</code></pre> <p>Verbosity level to pass to <code>read_raw_bids(..., verbose=read_raw_bids_verbose)</code>. If you know your dataset will contain files that are not perfectly BIDS compliant (e.g., \"Did not find any meg.json...\"), you can set this to <code>'error'</code> to suppress warnings emitted by read_raw_bids.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.analyze_channels","title":"analyze_channels  <code>module-attribute</code>","text":"Python<pre><code>analyze_channels = 'ch_types'\n</code></pre> <p>The names of the channels to analyze during ERP/ERF and time-frequency analysis steps. For certain paradigms, e.g. EEG ERP research, it is common to constrain sensor-space analysis to only a few specific sensors. If <code>'all'</code>, do not exclude any channels (except for those selected for removal via the <code>drop_channels</code> setting; use with caution as this can include things like STIM channels during the decoding step). If 'ch_types' (default), restrict to the channels listed in the <code>ch_types</code> parameter. The constraint will be applied to all sensor-level analyses after the preprocessing stage, but not to the preprocessing stage itself, nor to the source analysis stage.</p> Example <p>Only use channel <code>Pz</code> for ERP, evoked contrasts, time-by-time decoding, and time-frequency analysis: Python<pre><code>analyze_channels = ['Pz']\n</code></pre></p>"},{"location":"settings/general.html#mne_bids_pipeline._config.plot_psd_for_runs","title":"plot_psd_for_runs  <code>module-attribute</code>","text":"Python<pre><code>plot_psd_for_runs = 'all'\n</code></pre> <p>For which runs to add a power spectral density (PSD) plot to the generated report. This can take a considerable amount of time if you have many long runs. In this case, specify the runs, or pass an empty list to disable raw PSD plotting.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.n_jobs","title":"n_jobs  <code>module-attribute</code>","text":"Python<pre><code>n_jobs = 1\n</code></pre> <p>Specifies how many subjects you want to process in parallel. If <code>1</code>, disables parallel processing.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.parallel_backend","title":"parallel_backend  <code>module-attribute</code>","text":"Python<pre><code>parallel_backend = 'loky'\n</code></pre> <p>Specifies which backend to use for parallel job execution. <code>loky</code> is the default backend used by <code>joblib</code>. <code>dask</code> requires <code>Dask</code> to be installed. Ignored if <code>n_jobs</code> is set to <code>1</code>.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.dask_open_dashboard","title":"dask_open_dashboard  <code>module-attribute</code>","text":"Python<pre><code>dask_open_dashboard = False\n</code></pre> <p>Whether to open the Dask dashboard in the default webbrowser automatically. Ignored if <code>parallel_backend</code> is not <code>'dask'</code>.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.dask_temp_dir","title":"dask_temp_dir  <code>module-attribute</code>","text":"Python<pre><code>dask_temp_dir = None\n</code></pre> <p>The temporary directory to use by Dask. Dask places lock-files in this directory, and also uses it to \"spill\" RAM contents to disk if the amount of free memory in the system hits a critical low. It is recommended to point this to a location on a fast, local disk (i.e., not a network-attached storage) to ensure good performance. The directory needs to be writable and will be created if it does not exist.</p> <p>If <code>None</code>, will use <code>.dask-worker-space</code> inside of <code>deriv_root</code>.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.dask_worker_memory_limit","title":"dask_worker_memory_limit  <code>module-attribute</code>","text":"Python<pre><code>dask_worker_memory_limit = '10G'\n</code></pre> <p>The maximum amount of RAM per Dask worker.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.random_state","title":"random_state  <code>module-attribute</code>","text":"Python<pre><code>random_state = 42\n</code></pre> <p>You can specify the seed of the random number generator (RNG). This setting is passed to the ICA algorithm and to the decoding function, ensuring reproducible results. Set to <code>None</code> to avoid setting the RNG to a defined state.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.shortest_event","title":"shortest_event  <code>module-attribute</code>","text":"Python<pre><code>shortest_event = 1\n</code></pre> <p>Minimum number of samples an event must last. If the duration is less than this, an exception will be raised.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.memory_location","title":"memory_location  <code>module-attribute</code>","text":"Python<pre><code>memory_location = True\n</code></pre> <p>If not None (or False), caching will be enabled and the cache files will be stored in the given directory. The default (True) will use a <code>\"_cache\"</code> subdirectory (name configurable via the <code>memory_subdir</code> variable) in the BIDS derivative root of the dataset.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.memory_subdir","title":"memory_subdir  <code>module-attribute</code>","text":"Python<pre><code>memory_subdir = '_cache'\n</code></pre> <p>The caching directory name to use if <code>memory_location</code> is <code>True</code>.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.memory_file_method","title":"memory_file_method  <code>module-attribute</code>","text":"Python<pre><code>memory_file_method = 'mtime'\n</code></pre> <p>The method to use for cache invalidation (i.e., detecting changes). Using the \"modified time\" reported by the filesystem (<code>'mtime'</code>, default) is very fast but requires that the filesystem supports proper mtime reporting. Using file hashes (<code>'hash'</code>) is slower and requires reading all input files but should work on any filesystem.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.memory_verbose","title":"memory_verbose  <code>module-attribute</code>","text":"Python<pre><code>memory_verbose = 0\n</code></pre> <p>The verbosity to use when using memory. The default (0) does not print, while 1 will print the function calls that will be cached. See the documentation for the joblib.Memory class for more information.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.config_validation","title":"config_validation  <code>module-attribute</code>","text":"Python<pre><code>config_validation = 'raise'\n</code></pre> <p>How strictly to validate the configuration. Errors are always raised for invalid entries (e.g., not providing <code>ch_types</code>). This setting controls how to handle possibly or likely incorrect entries, such as likely misspellings (e.g., providing <code>session</code> instead of <code>sessions</code>).</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.log_level","title":"log_level  <code>module-attribute</code>","text":"Python<pre><code>log_level = 'info'\n</code></pre> <p>Set the pipeline logging verbosity.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.mne_log_level","title":"mne_log_level  <code>module-attribute</code>","text":"Python<pre><code>mne_log_level = 'error'\n</code></pre> <p>Set the MNE-Python logging verbosity.</p>"},{"location":"settings/general.html#mne_bids_pipeline._config.on_error","title":"on_error  <code>module-attribute</code>","text":"Python<pre><code>on_error = 'abort'\n</code></pre> <p>Whether to abort processing as soon as an error occurs, continue with all other processing steps for as long as possible, or drop you into a debugger in case of an error.</p> <p>Info</p> <p>Enabling debug mode deactivates parallel processing.</p>"},{"location":"settings/preprocessing/artifacts.html","title":"Amplitude-based artifact rejection","text":"Good Practice / Advice <p>Have a look at your raw data and train yourself to detect a blink, a heart beat and an eye movement. You can do a quick average of blink data and check what the amplitude looks like.</p>","tags":["preprocessing","artifact-removal","epochs"]},{"location":"settings/preprocessing/artifacts.html#mne_bids_pipeline._config.reject","title":"reject  <code>module-attribute</code>","text":"Python<pre><code>reject = None\n</code></pre> <p>Peak-to-peak amplitude limits to mark epochs as bad. This allows you to remove epochs with strong transient artifacts.</p> <p>Info</p> <p>The rejection is performed after SSP or ICA, if any of those methods   is used. To reject epochs before fitting ICA, see the   <code>ica_reject</code> setting.</p> <p>If <code>None</code> (default), do not apply artifact rejection.</p> <p>If a dictionary, manually specify rejection thresholds (see examples).  The thresholds provided here must be at least as stringent as those in <code>ica_reject</code> if using ICA. In case of <code>'autoreject_global'</code>, thresholds for any channel that do not meet this requirement will be automatically replaced with those used in <code>ica_reject</code>.</p> <p>If <code>\"autoreject_global\"</code>, use <code>autoreject</code> to find suitable \"global\" rejection thresholds for each channel type, i.e., <code>autoreject</code> will generate a dictionary with (hopefully!) optimal thresholds for each channel type.</p> <p>If <code>\"autoreject_local\"</code>, use \"local\" <code>autoreject</code> to detect (and potentially repair) bad channels in each epoch. Use <code>autoreject_n_interpolate</code> to control how many channels are allowed to be bad before an epoch gets dropped.</p> Example Python<pre><code>reject = {\"grad\": 4000e-13, 'mag': 4e-12, 'eog': 150e-6}\nreject = {\"eeg\": 100e-6, \"eog\": 250e-6}\nreject = None  # no rejection based on PTP amplitude\nreject = \"autoreject_global\"  # find global (per channel type) PTP thresholds\nreject = \"autoreject_local\"  # find local (per channel) thresholds and repair epochs\n</code></pre>","tags":["preprocessing","artifact-removal","epochs"]},{"location":"settings/preprocessing/artifacts.html#mne_bids_pipeline._config.reject_tmin","title":"reject_tmin  <code>module-attribute</code>","text":"Python<pre><code>reject_tmin = None\n</code></pre> <p>Start of the time window used to reject epochs. If <code>None</code>, the window will start with the first time point. Has no effect if <code>reject</code> has been set to <code>\"autoreject_local\"</code>.</p> Example Python<pre><code>reject_tmin = -0.1  # 100 ms before event onset.\n</code></pre>","tags":["preprocessing","artifact-removal","epochs"]},{"location":"settings/preprocessing/artifacts.html#mne_bids_pipeline._config.reject_tmax","title":"reject_tmax  <code>module-attribute</code>","text":"Python<pre><code>reject_tmax = None\n</code></pre> <p>End of the time window used to reject epochs. If <code>None</code>, the window will end with the last time point. Has no effect if <code>reject</code> has been set to <code>\"autoreject_local\"</code>.</p> Example Python<pre><code>reject_tmax = 0.3  # 300 ms after event onset.\n</code></pre>","tags":["preprocessing","artifact-removal","epochs"]},{"location":"settings/preprocessing/artifacts.html#mne_bids_pipeline._config.autoreject_n_interpolate","title":"autoreject_n_interpolate  <code>module-attribute</code>","text":"Python<pre><code>autoreject_n_interpolate = [4, 8, 16]\n</code></pre> <p>The maximum number of bad channels in an epoch that <code>autoreject</code> local will try to interpolate. The optimal number among this list will be estimated using a cross-validation procedure; this means that the more elements are provided here, the longer the <code>autoreject</code> run will take. If the number of bad channels in an epoch exceeds this value, the channels won't be interpolated and the epoch will be dropped.</p> <p>Info</p> <p>This setting only takes effect if <code>reject</code> has been set to <code>\"autoreject_local\"</code>.</p> <p>Info</p> <p>Channels marked as globally bad in the BIDS dataset (in <code>*_channels.tsv)</code>) will not be considered (i.e., will remain marked as bad and not analyzed by autoreject).</p>","tags":["preprocessing","artifact-removal","epochs"]},{"location":"settings/preprocessing/autobads.html","title":"Bad channel detection","text":"<p>Warning</p> <p>This functionality will soon be removed from the pipeline, and will be integrated into MNE-BIDS.</p> <p>\"Bad\", i.e. flat and overly noisy channels, can be automatically detected using a procedure inspired by the commercial MaxFilter by Elekta. First, a copy of the data is low-pass filtered at 40 Hz. Then, channels with unusually low variability are flagged as \"flat\", while channels with excessively high variability are flagged as \"noisy\". Flat and noisy channels are marked as \"bad\" and excluded from subsequent analysis. See :func:<code>mne.preprocssessing.find_bad_channels_maxwell</code> for more information on this procedure. The list of bad channels detected through this procedure will be merged with the list of bad channels already present in the dataset, if any.</p>","tags":["preprocessing","raw","bad-channels"]},{"location":"settings/preprocessing/autobads.html#mne_bids_pipeline._config.find_flat_channels_meg","title":"find_flat_channels_meg  <code>module-attribute</code>","text":"Python<pre><code>find_flat_channels_meg = False\n</code></pre> <p>Auto-detect \"flat\" channels (i.e. those with unusually low variability) and mark them as bad.</p>","tags":["preprocessing","raw","bad-channels"]},{"location":"settings/preprocessing/autobads.html#mne_bids_pipeline._config.find_noisy_channels_meg","title":"find_noisy_channels_meg  <code>module-attribute</code>","text":"Python<pre><code>find_noisy_channels_meg = False\n</code></pre> <p>Auto-detect \"noisy\" channels and mark them as bad.</p>","tags":["preprocessing","raw","bad-channels"]},{"location":"settings/preprocessing/breaks.html","title":"Break detection","text":"","tags":["preprocessing","artifact-removal","raw","events"]},{"location":"settings/preprocessing/breaks.html#mne_bids_pipeline._config.find_breaks","title":"find_breaks  <code>module-attribute</code>","text":"Python<pre><code>find_breaks = False\n</code></pre> <p>During an experimental run, the recording might be interrupted by breaks of various durations, e.g. to allow the participant to stretch, blink, and swallow freely. During these periods, large-scale artifacts are often picked up by the recording system. These artifacts can impair certain stages of processing, e.g. the peak-detection algorithms we use to find EOG and ECG activity. In some cases, even the bad channel detection algorithms might not function optimally. It is therefore advisable to mark such break periods for exclusion at early processing stages.</p> <p>If <code>True</code>, try to mark breaks by finding segments of the data where no experimental events have occurred. This will then add annotations with the description <code>BAD_break</code> to the continuous data, causing these segments to be ignored in all following processing steps.</p> Example <p>Automatically find break periods, and annotate them as <code>BAD_break</code>. Python<pre><code>find_breaks = True\n</code></pre></p> <p>Disable break detection. Python<pre><code>find_breaks = False\n</code></pre></p>","tags":["preprocessing","artifact-removal","raw","events"]},{"location":"settings/preprocessing/breaks.html#mne_bids_pipeline._config.min_break_duration","title":"min_break_duration  <code>module-attribute</code>","text":"Python<pre><code>min_break_duration = 15.0\n</code></pre> <p>The minimal duration (in seconds) of a data segment without any experimental events for it to be considered a \"break\". Note that the minimal duration of the generated <code>BAD_break</code> annotation will typically be smaller than this, as by default, the annotation will not extend across the entire break. See <code>t_break_annot_start_after_previous_event</code> and <code>t_break_annot_stop_before_next_event</code> to control this behavior.</p> Example <p>Periods between two consecutive experimental events must span at least <code>15</code> seconds for this period to be considered a \"break\". Python<pre><code>min_break_duration = 15.\n</code></pre></p>","tags":["preprocessing","artifact-removal","raw","events"]},{"location":"settings/preprocessing/breaks.html#mne_bids_pipeline._config.t_break_annot_start_after_previous_event","title":"t_break_annot_start_after_previous_event  <code>module-attribute</code>","text":"Python<pre><code>t_break_annot_start_after_previous_event = 5.0\n</code></pre> <p>Once a break of at least <code>min_break_duration</code> seconds has been discovered, we generate a <code>BAD_break</code> annotation that does not necessarily span the entire break period. Instead, you will typically want to start it some time after the last event before the break period, as to not unnecessarily discard brain activity immediately following that event.</p> <p>This parameter controls how much time (in seconds) should pass after the last pre-break event before we start annotating the following segment of the break period as bad.</p> Example <p>Once a break period has been detected, add a <code>BAD_break</code> annotation to it, starting <code>5</code> seconds after the latest pre-break event. Python<pre><code>t_break_annot_start_after_previous_event = 5.\n</code></pre></p> <p>Start the <code>BAD_break</code> annotation immediately after the last pre-break event. Python<pre><code>t_break_annot_start_after_previous_event = 0.\n</code></pre></p>","tags":["preprocessing","artifact-removal","raw","events"]},{"location":"settings/preprocessing/breaks.html#mne_bids_pipeline._config.t_break_annot_stop_before_next_event","title":"t_break_annot_stop_before_next_event  <code>module-attribute</code>","text":"Python<pre><code>t_break_annot_stop_before_next_event = 5.0\n</code></pre> <p>Similarly to how <code>t_break_annot_start_after_previous_event</code> controls the \"gap\" between beginning of the break period and <code>BAD_break</code> annotation onset,  this parameter controls how far the annotation should extend toward the first experimental event immediately following the break period (in seconds). This can help not to waste a post-break trial by marking its pre-stimulus period as bad.</p> Example <p>Once a break period has been detected, add a <code>BAD_break</code> annotation to it, starting <code>5</code> seconds after the latest pre-break event. Python<pre><code>t_break_annot_start_after_previous_event = 5.\n</code></pre></p> <p>Start the <code>BAD_break</code> annotation immediately after the last pre-break event. Python<pre><code>t_break_annot_start_after_previous_event = 0.\n</code></pre></p>","tags":["preprocessing","artifact-removal","raw","events"]},{"location":"settings/preprocessing/epochs.html","title":"Epoching","text":"","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.rename_events","title":"rename_events  <code>module-attribute</code>","text":"Python<pre><code>rename_events = dict()\n</code></pre> <p>A dictionary specifying which events in the BIDS dataset to rename upon loading, and before processing begins.</p> <p>Pass an empty dictionary to not perform any renaming.</p> Example <p>Rename <code>audio_left</code> in the BIDS dataset to <code>audio/left</code> in the pipeline: Python<pre><code>rename_events = {'audio_left': 'audio/left'}\n</code></pre></p>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.on_rename_missing_events","title":"on_rename_missing_events  <code>module-attribute</code>","text":"Python<pre><code>on_rename_missing_events = 'raise'\n</code></pre> <p>How to handle the situation where you specified an event to be renamed via <code>rename_events</code>, but this particular event is not present in the data. By default, we will raise an exception to avoid accidental mistakes due to typos; however, if you're sure what you're doing, you may change this to <code>'warn'</code> to only get a warning instead, or <code>'ignore'</code> to ignore it completely.</p>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.event_repeated","title":"event_repeated  <code>module-attribute</code>","text":"Python<pre><code>event_repeated = 'error'\n</code></pre> <p>How to handle repeated events. We call events \"repeated\" if more than one event occurred at the exact same time point. Currently, MNE-Python cannot handle this situation gracefully when trying to create epochs, and will throw an error. To only keep the event of that time point (\"first\" here referring to the order that events appear in <code>*_events.tsv</code>), pass <code>'drop'</code>. You can also request to create a new type of event by merging repeated events by setting this to <code>'merge'</code>.</p> <p>Warning</p> <p>The <code>'merge'</code> option is entirely untested in the MNE BIDS Pipeline as of April 1st, 2021.</p>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.conditions","title":"conditions  <code>module-attribute</code>","text":"Python<pre><code>conditions = None\n</code></pre> <p>The time-locked events based on which to create evoked responses. This can either be name of the experimental condition as specified in the BIDS <code>*_events.tsv</code> file; or the name of condition groups, if the condition names contain the (MNE-specific) group separator, <code>/</code>. See the Subselecting epochs tutorial for more information.</p> <p>Passing a dictionary allows to assign a name to map a complex condition name (value) to a more legible one (value).</p> <p>This is a required parameter in the configuration file, unless you are processing resting-state data. If left as <code>None</code> and <code>task_is_rest</code> is not <code>True</code>, we will raise an error.</p> Example <p>Specifying conditions as lists of strings: Python<pre><code>conditions = ['auditory/left', 'visual/left']\nconditions = ['auditory/left', 'auditory/right']\nconditions = ['auditory']  # All \"auditory\" conditions (left AND right)\nconditions = ['auditory', 'visual']\nconditions = ['left', 'right']\nconditions = None  # for a resting-state analysis\n</code></pre> Pass a dictionary to define a mapping: ```python conditions = {'simple_name': 'complex/condition/with_subconditions'} conditions = {'correct': 'response/correct',               'incorrect': 'response/incorrect'}</p>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.epochs_tmin","title":"epochs_tmin  <code>module-attribute</code>","text":"Python<pre><code>epochs_tmin = -0.2\n</code></pre> <p>The beginning of an epoch, relative to the respective event, in seconds.</p> Example Python<pre><code>epochs_tmin = -0.2  # 200 ms before event onset\n</code></pre>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.epochs_tmax","title":"epochs_tmax  <code>module-attribute</code>","text":"Python<pre><code>epochs_tmax = 0.5\n</code></pre> <p>The end of an epoch, relative to the respective event, in seconds.</p> Example Python<pre><code>epochs_tmax = 0.5  # 500 ms after event onset\n</code></pre>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.baseline","title":"baseline  <code>module-attribute</code>","text":"Python<pre><code>baseline = (None, 0)\n</code></pre> <p>Specifies which time interval to use for baseline correction of epochs; if <code>None</code>, no baseline correction is applied.</p> Example Python<pre><code>baseline = (None, 0)  # beginning of epoch until time point zero\n</code></pre>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.epochs_metadata_tmin","title":"epochs_metadata_tmin  <code>module-attribute</code>","text":"Python<pre><code>epochs_metadata_tmin = None\n</code></pre> <p>The beginning of the time window for metadata generation, in seconds, relative to the time-locked event of the respective epoch. This may be less than or larger than the epoch's first time point. If <code>None</code>, use the first time point of the epoch.</p>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.epochs_metadata_tmax","title":"epochs_metadata_tmax  <code>module-attribute</code>","text":"Python<pre><code>epochs_metadata_tmax = None\n</code></pre> <p>Same as <code>epochs_metadata_tmin</code>, but specifying the end of the time window for metadata generation.</p>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.epochs_metadata_keep_first","title":"epochs_metadata_keep_first  <code>module-attribute</code>","text":"Python<pre><code>epochs_metadata_keep_first = None\n</code></pre> <p>Event groupings using hierarchical event descriptors (HEDs) for which to store the time of the first occurrence of any event of this group in a new column with the group name, and the type of that event in a column named after the group, but with a <code>first_</code> prefix. If <code>None</code> (default), no event aggregation will take place and no new columns will be created.</p> Example <p>Assume you have two response events types, <code>response/left</code> and <code>response/right</code>; in some trials, both responses occur, because the participant pressed both buttons. Now, you want to keep the first response only. To achieve this, set Python<pre><code>epochs_metadata_keep_first = ['response']\n</code></pre> This will add two new columns to the metadata: <code>response</code>, indicating the time relative to the time-locked event; and <code>first_response</code>, depicting the type of event (<code>'left'</code> or <code>'right'</code>).</p> <p>You may also specify a grouping for multiple event types: Python<pre><code>epochs_metadata_keep_first = ['response', 'stimulus']\n</code></pre> This will add the columns <code>response</code>, <code>first_response</code>, <code>stimulus</code>, and <code>first_stimulus</code>.</p>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.epochs_metadata_keep_last","title":"epochs_metadata_keep_last  <code>module-attribute</code>","text":"Python<pre><code>epochs_metadata_keep_last = None\n</code></pre> <p>Same as <code>epochs_metadata_keep_first</code>, but for keeping the last occurrence of matching event types. The columns indicating the event types will be named with a <code>last_</code> instead of a <code>first_</code> prefix.</p>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.epochs_metadata_query","title":"epochs_metadata_query  <code>module-attribute</code>","text":"Python<pre><code>epochs_metadata_query = None\n</code></pre> <p>A [metadata query][https://mne.tools/stable/auto_tutorials/epochs/30_epochs_metadata.html] specifying which epochs to keep. If the query fails because it refers to an unknown metadata column, a warning will be emitted and all epochs will be kept.</p> Example <p>Only keep epochs without a <code>response_missing</code> event: Python<pre><code>epochs_metadata_query = ['response_missing.isna()']\n</code></pre></p>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.rest_epochs_duration","title":"rest_epochs_duration  <code>module-attribute</code>","text":"Python<pre><code>rest_epochs_duration = None\n</code></pre> <p>Duration of epochs in seconds.</p>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/epochs.html#mne_bids_pipeline._config.rest_epochs_overlap","title":"rest_epochs_overlap  <code>module-attribute</code>","text":"Python<pre><code>rest_epochs_overlap = None\n</code></pre> <p>Overlap between epochs in seconds. This is used if the task is <code>'rest'</code> and when the annotations do not contain any stimulation or behavior events.</p>","tags":["preprocessing","epochs","events","metadata","resting-state"]},{"location":"settings/preprocessing/filter.html","title":"Filtering","text":"<p>It is typically better to set your filtering properties on the raw data so as to avoid what we call border (or edge) effects.</p> <p>If you use this pipeline for evoked responses, you could consider a low-pass filter cut-off of h_freq = 40 Hz and possibly a high-pass filter cut-off of l_freq = 1 Hz so you would preserve only the power in the 1Hz to 40 Hz band. Note that highpass filtering is not necessarily recommended as it can distort waveforms of evoked components, or simply wash out any low frequency that can may contain brain signal. It can also act as a replacement for baseline correction in Epochs. See below.</p> <p>If you use this pipeline for time-frequency analysis, a default filtering could be a high-pass filter cut-off of l_freq = 1 Hz a low-pass filter cut-off of h_freq = 120 Hz so you would preserve only the power in the 1Hz to 120 Hz band.</p> <p>If you need more fancy analysis, you are already likely past this kind of tips! \ud83d\ude07</p>","tags":["preprocessing","frequency-filter","raw"]},{"location":"settings/preprocessing/filter.html#mne_bids_pipeline._config.l_freq","title":"l_freq  <code>module-attribute</code>","text":"Python<pre><code>l_freq = None\n</code></pre> <p>The low-frequency cut-off in the highpass filtering step. Keep it <code>None</code> if no highpass filtering should be applied.</p>","tags":["preprocessing","frequency-filter","raw"]},{"location":"settings/preprocessing/filter.html#mne_bids_pipeline._config.h_freq","title":"h_freq  <code>module-attribute</code>","text":"Python<pre><code>h_freq = 40.0\n</code></pre> <p>The high-frequency cut-off in the lowpass filtering step. Keep it <code>None</code> if no lowpass filtering should be applied.</p>","tags":["preprocessing","frequency-filter","raw"]},{"location":"settings/preprocessing/filter.html#mne_bids_pipeline._config.l_trans_bandwidth","title":"l_trans_bandwidth  <code>module-attribute</code>","text":"Python<pre><code>l_trans_bandwidth = 'auto'\n</code></pre> <p>Specifies the transition bandwidth of the highpass filter. By default it's <code>'auto'</code> and uses default MNE parameters.</p>","tags":["preprocessing","frequency-filter","raw"]},{"location":"settings/preprocessing/filter.html#mne_bids_pipeline._config.h_trans_bandwidth","title":"h_trans_bandwidth  <code>module-attribute</code>","text":"Python<pre><code>h_trans_bandwidth = 'auto'\n</code></pre> <p>Specifies the transition bandwidth of the lowpass filter. By default it's <code>'auto'</code> and uses default MNE parameters.</p>","tags":["preprocessing","frequency-filter","raw"]},{"location":"settings/preprocessing/filter.html#mne_bids_pipeline._config.notch_freq","title":"notch_freq  <code>module-attribute</code>","text":"Python<pre><code>notch_freq = None\n</code></pre> <p>Notch filter frequency. More than one frequency can be supplied, e.g. to remove harmonics. Keep it <code>None</code> if no notch filter should be applied.</p> <p>Info</p> <p>The notch filter will be applied before high- and lowpass filtering.</p> Example <p>Remove line noise at 50 Hz: Python<pre><code>notch_freq = 50\n</code></pre> Remove line noise at 50 Hz and its (sub-)harmonics Python<pre><code>notch_freq = [25, 50, 100, 150]\n</code></pre></p>","tags":["preprocessing","frequency-filter","raw"]},{"location":"settings/preprocessing/filter.html#mne_bids_pipeline._config.notch_trans_bandwidth","title":"notch_trans_bandwidth  <code>module-attribute</code>","text":"Python<pre><code>notch_trans_bandwidth = 1.0\n</code></pre> <p>Specifies the transition bandwidth of the notch filter. The default is <code>1.</code>.</p>","tags":["preprocessing","frequency-filter","raw"]},{"location":"settings/preprocessing/filter.html#mne_bids_pipeline._config.notch_widths","title":"notch_widths  <code>module-attribute</code>","text":"Python<pre><code>notch_widths = None\n</code></pre> <p>Specifies the width of each stop band. <code>None</code> uses the MNE default.</p>","tags":["preprocessing","frequency-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html","title":"Maxwell filter","text":"","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.use_maxwell_filter","title":"use_maxwell_filter  <code>module-attribute</code>","text":"Python<pre><code>use_maxwell_filter = False\n</code></pre> <p>Whether or not to use Maxwell filtering to preprocess the data.</p> <p>Warning</p> <p>If the data were recorded with internal active compensation (MaxShield), they need to be run through Maxwell filter to avoid distortions. Bad channels need to be set through BIDS channels.tsv and / or via the <code>find_flat_channels_meg</code> and <code>find_noisy_channels_meg</code> options above before applying Maxwell filter.</p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_st_duration","title":"mf_st_duration  <code>module-attribute</code>","text":"Python<pre><code>mf_st_duration = None\n</code></pre> <p>There are two kinds of Maxwell filtering: SSS (signal space separation) and tSSS (temporal signal space separation) (see Taulu et al., 2004).</p> <p>If not None, apply spatiotemporal SSS (tSSS) with specified buffer duration (in seconds). MaxFilter\u2122's default is 10.0 seconds in v2.2. Spatiotemporal SSS acts as implicitly as a high-pass filter where the cut-off frequency is 1/st_dur Hz. For this (and other) reasons, longer buffers are generally better as long as your system can handle the higher memory usage. To ensure that each window is processed identically, choose a buffer length that divides evenly into your data. Any data at the trailing edge that doesn't fit evenly into a whole buffer window will be lumped into the previous buffer.</p> Good Practice / Advice <p>If you are interested in low frequency activity (&lt;0.1Hz), avoid using tSSS and set <code>mf_st_duration</code> to <code>None</code>.</p> <p>If you are interested in low frequency above 0.1 Hz, you can use the default <code>mf_st_duration</code> to 10 s, meaning it acts like a 0.1 Hz high-pass filter.</p> Example Python<pre><code>mf_st_duration = None\nmf_st_duration = 10.  # to apply tSSS with 0.1Hz highpass filter.\n</code></pre>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_st_correlation","title":"mf_st_correlation  <code>module-attribute</code>","text":"Python<pre><code>mf_st_correlation = 0.98\n</code></pre> <p>The correlation limit for spatio-temporal SSS (tSSS).</p> Example Python<pre><code>st_correlation = 0.98\n</code></pre>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_head_origin","title":"mf_head_origin  <code>module-attribute</code>","text":"Python<pre><code>mf_head_origin = 'auto'\n</code></pre> <p><code>mf_head_origin</code> : array-like, shape (3,) | 'auto' Origin of internal and external multipolar moment space in meters. If 'auto', it will be estimated from headshape points. If automatic fitting fails (e.g., due to having too few digitization points), consider separately calling the fitting function with different options or specifying the origin manually.</p> Example Python<pre><code>mf_head_origin = 'auto'\n</code></pre>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_destination","title":"mf_destination  <code>module-attribute</code>","text":"Python<pre><code>mf_destination = 'reference_run'\n</code></pre> <p>Despite all possible care to avoid movements in the MEG, the participant will likely slowly drift down from the Dewar or slightly shift the head around in the course of the recording session. Hence, to take this into account, we are realigning all data to a single position. For this, you can:</p> <ol> <li>Choose a reference run. Often one from the middle of the recording session    is a good choice. Set <code>mf_destination = \"reference_run\" and then set    [</code>config.mf_reference_run`][mne_bids_pipeline._config.mf_reference_run].    This will result in a device-to-head transformation that differs between    subjects.</li> <li>Choose a standard position in the MEG coordinate frame. For this, pass    a 4x4 transformation matrix for the device-to-head    transform. This will result in a device-to-head transformation that is    the same across all subjects.</li> </ol> <p>???+ example \"A Standardized Position\"    Python<pre><code>from mne.transforms import translation\nmf_destination = translation(z=0.04)\n</code></pre></p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_int_order","title":"mf_int_order  <code>module-attribute</code>","text":"Python<pre><code>mf_int_order = 8\n</code></pre> <p>Internal order for the Maxwell basis. Can be set to something lower (e.g., 6 or higher for datasets where lower or higher spatial complexity, respectively, is expected.</p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_reference_run","title":"mf_reference_run  <code>module-attribute</code>","text":"Python<pre><code>mf_reference_run = None\n</code></pre> <p>Which run to take as the reference for adjusting the head position of all runs when <code>mf_destination=\"reference_run\"</code>. If <code>None</code>, pick the first run.</p> Example Python<pre><code>mf_reference_run = '01'  # Use run \"01\"\n</code></pre>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_cal_fname","title":"mf_cal_fname  <code>module-attribute</code>","text":"Python<pre><code>mf_cal_fname = None\n</code></pre> <p>Warning</p> <p>This parameter should only be used for BIDS datasets that don't store  the fine-calibration file  according to BIDS.</p> <p>Path to the Maxwell Filter calibration file. If <code>None</code>, the recommended location is used.</p> Example Python<pre><code>mf_cal_fname = '/path/to/your/file/calibration_cal.dat'\n</code></pre>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_ctc_fname","title":"mf_ctc_fname  <code>module-attribute</code>","text":"Python<pre><code>mf_ctc_fname = None\n</code></pre> <p>Path to the Maxwell Filter cross-talk file. If <code>None</code>, the recommended location is used.</p> <p>Warning</p> <p>This parameter should only be used for BIDS datasets that don't store  the cross-talk file  according to BIDS.</p> Example Python<pre><code>mf_ctc_fname = '/path/to/your/file/crosstalk_ct.fif'\n</code></pre>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_esss","title":"mf_esss  <code>module-attribute</code>","text":"Python<pre><code>mf_esss = 0\n</code></pre> <p>Number of extended SSS (eSSS) basis projectors to use from empty-room data.</p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_esss_reject","title":"mf_esss_reject  <code>module-attribute</code>","text":"Python<pre><code>mf_esss_reject = None\n</code></pre> <p>Rejection parameters to use when computing the extended SSS (eSSS) basis.</p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_mc","title":"mf_mc  <code>module-attribute</code>","text":"Python<pre><code>mf_mc = False\n</code></pre> <p>If True, perform movement compensation on the data.</p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_mc_t_step_min","title":"mf_mc_t_step_min  <code>module-attribute</code>","text":"Python<pre><code>mf_mc_t_step_min = 0.01\n</code></pre> <p>Minimum time step to use during cHPI coil amplitude estimation.</p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_mc_t_window","title":"mf_mc_t_window  <code>module-attribute</code>","text":"Python<pre><code>mf_mc_t_window = 'auto'\n</code></pre> <p>The window to use during cHPI coil amplitude estimation and in cHPI filtering. Can be \"auto\" to autodetect a reasonable value or a float (in seconds).</p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_mc_gof_limit","title":"mf_mc_gof_limit  <code>module-attribute</code>","text":"Python<pre><code>mf_mc_gof_limit = 0.98\n</code></pre> <p>Minimum goodness of fit to accept for each cHPI coil.</p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_mc_dist_limit","title":"mf_mc_dist_limit  <code>module-attribute</code>","text":"Python<pre><code>mf_mc_dist_limit = 0.005\n</code></pre> <p>Minimum distance (m) to accept for cHPI position fitting.</p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_mc_rotation_velocity_limit","title":"mf_mc_rotation_velocity_limit  <code>module-attribute</code>","text":"Python<pre><code>mf_mc_rotation_velocity_limit = None\n</code></pre> <p>The rotation velocity limit (degrees/second) to use when annotating movement-compensated data. If <code>None</code>, no annotations will be added.</p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_mc_translation_velocity_limit","title":"mf_mc_translation_velocity_limit  <code>module-attribute</code>","text":"Python<pre><code>mf_mc_translation_velocity_limit = None\n</code></pre> <p>The translation velocity limit (meters/second) to use when annotating movement-compensated data. If <code>None</code>, no annotations will be added.</p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/maxfilter.html#mne_bids_pipeline._config.mf_filter_chpi","title":"mf_filter_chpi  <code>module-attribute</code>","text":"Python<pre><code>mf_filter_chpi = None\n</code></pre> <p>Use mne.chpi.filter_chpi after Maxwell filtering. Can be None to use the same value as <code>mf_mc</code>. Only used when <code>use_maxwell_filter=True</code></p>","tags":["preprocessing","maxwell-filter","raw"]},{"location":"settings/preprocessing/resample.html","title":"Resampling","text":"<p>If you have acquired data with a very high sampling frequency (e.g. 2 kHz) you will likely want to downsample to lighten up the size of the files you are working with (pragmatics) If you are interested in typical analysis (up to 120 Hz) you can typically resample your data down to 500 Hz without preventing reliable time-frequency exploration of your data.</p>","tags":["preprocessing","resampling","decimation","raw","epochs"]},{"location":"settings/preprocessing/resample.html#mne_bids_pipeline._config.raw_resample_sfreq","title":"raw_resample_sfreq  <code>module-attribute</code>","text":"Python<pre><code>raw_resample_sfreq = None\n</code></pre> <p>Specifies at which sampling frequency the data should be resampled. If <code>None</code>, then no resampling will be done.</p> Example Python<pre><code>raw_resample_sfreq = None  # no resampling\nraw_resample_sfreq = 500  # resample to 500Hz\n</code></pre>","tags":["preprocessing","resampling","decimation","raw","epochs"]},{"location":"settings/preprocessing/resample.html#mne_bids_pipeline._config.epochs_decim","title":"epochs_decim  <code>module-attribute</code>","text":"Python<pre><code>epochs_decim = 1\n</code></pre> <p>Says how much to decimate data at the epochs level. It is typically an alternative to the <code>resample_sfreq</code> parameter that can be used for resampling raw data. <code>1</code> means no decimation.</p> Good Practice / Advice <p>Decimation requires to lowpass filtered the data to avoid aliasing. Note that using decimation is much faster than resampling.</p> Example Python<pre><code>epochs_decim = 1  # no decimation\nepochs_decim = 4  # decimate by 4, i.e., divide sampling frequency by 4\n</code></pre>","tags":["preprocessing","resampling","decimation","raw","epochs"]},{"location":"settings/preprocessing/ssp_ica.html","title":"SSP & ICA","text":"","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.spatial_filter","title":"spatial_filter  <code>module-attribute</code>","text":"Python<pre><code>spatial_filter = None\n</code></pre> <p>Whether to use a spatial filter to detect and remove artifacts. The BIDS Pipeline offers the use of signal-space projection (SSP) and independent component analysis (ICA).</p> <p>Use <code>'ssp'</code> for SSP, <code>'ica'</code> for ICA, and <code>None</code> if you do not wish to apply a spatial filter for artifact removal.</p> <p>The Pipeline will try to automatically discover EOG and ECG artifacts. For SSP, it will then produce projection vectors that remove (\"project out\") these artifacts from the data. For ICA, the independent components related to EOG and ECG activity will be omitted during the signal reconstruction step in order to remove the artifacts. The ICA procedure can be configured in various ways using the configuration options you can find below.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.min_ecg_epochs","title":"min_ecg_epochs  <code>module-attribute</code>","text":"Python<pre><code>min_ecg_epochs = 5\n</code></pre> <p>Minimal number of ECG epochs needed to compute SSP or ICA rejection.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.min_eog_epochs","title":"min_eog_epochs  <code>module-attribute</code>","text":"Python<pre><code>min_eog_epochs = 5\n</code></pre> <p>Minimal number of EOG epochs needed to compute SSP or ICA rejection.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.n_proj_eog","title":"n_proj_eog  <code>module-attribute</code>","text":"Python<pre><code>n_proj_eog = dict(n_mag=1, n_grad=1, n_eeg=1)\n</code></pre> <p>Number of SSP vectors to create for EOG artifacts for each channel type.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.n_proj_ecg","title":"n_proj_ecg  <code>module-attribute</code>","text":"Python<pre><code>n_proj_ecg = dict(n_mag=1, n_grad=1, n_eeg=1)\n</code></pre> <p>Number of SSP vectors to create for ECG artifacts for each channel type.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ssp_meg","title":"ssp_meg  <code>module-attribute</code>","text":"Python<pre><code>ssp_meg = 'auto'\n</code></pre> <p>Whether to compute SSP vectors for MEG channels separately (<code>'separate'</code>) or jointly (<code>'combined'</code>) for magnetometers and gradiomenters. When using Maxwell filtering, magnetometer and gradiometer signals are synthesized from multipole moments jointly and are no longer independent, so it can be useful to estimate projectors from all MEG sensors simultaneously. The default is <code>'auto'</code>, which will use <code>'combined'</code> when Maxwell filtering is used and <code>'separate'</code> otherwise.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ecg_proj_from_average","title":"ecg_proj_from_average  <code>module-attribute</code>","text":"Python<pre><code>ecg_proj_from_average = True\n</code></pre> <p>Whether to calculate the ECG projection vectors based on the the averaged or on individual ECG epochs.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.eog_proj_from_average","title":"eog_proj_from_average  <code>module-attribute</code>","text":"Python<pre><code>eog_proj_from_average = True\n</code></pre> <p>Whether to calculate the EOG projection vectors based on the the averaged or on individual EOG epochs.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ssp_reject_eog","title":"ssp_reject_eog  <code>module-attribute</code>","text":"Python<pre><code>ssp_reject_eog = None\n</code></pre> <p>Peak-to-peak amplitude limits of the EOG epochs to exclude from SSP fitting. This allows you to remove strong transient artifacts, which could negatively affect SSP performance.</p> <p>The pipeline will automatically try to detect EOG artifacts in your data, and remove them via SSP. For this to work properly, it is recommended to not specify rejection thresholds for EOG channels here \u2013 otherwise, SSP won't be able to \"see\" these artifacts.</p> Example Python<pre><code>ssp_reject_eog = {'grad': 10e-10, 'mag': 20e-12, 'eeg': 400e-6}\nssp_reject_eog = {'grad': 15e-10}\nssp_reject_eog = None\n</code></pre>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ssp_reject_ecg","title":"ssp_reject_ecg  <code>module-attribute</code>","text":"Python<pre><code>ssp_reject_ecg = None\n</code></pre> <p>Peak-to-peak amplitude limits of the ECG epochs to exclude from SSP fitting. This allows you to remove strong transient artifacts, which could negatively affect SSP performance.</p> <p>The pipeline will automatically try to detect ECG artifacts in your data, and remove them via SSP. For this to work properly, it is recommended to not specify rejection thresholds for ECG channels here \u2013 otherwise, SSP won't be able to \"see\" these artifacts.</p> Example Python<pre><code>ssp_reject_ecg = {'grad': 10e-10, 'mag': 20e-12, 'eeg': 400e-6}\nssp_reject_ecg = {'grad': 15e-10}\nssp_reject_ecg = None\n</code></pre>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ssp_ecg_channel","title":"ssp_ecg_channel  <code>module-attribute</code>","text":"Python<pre><code>ssp_ecg_channel = None\n</code></pre> <p>Channel to use for ECG SSP. Can be useful when the autodetected ECG channel is not reliable.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ica_reject","title":"ica_reject  <code>module-attribute</code>","text":"Python<pre><code>ica_reject = None\n</code></pre> <p>Peak-to-peak amplitude limits to exclude epochs from ICA fitting. This allows you to remove strong transient artifacts from the epochs used for fitting ICA, which could negatively affect ICA performance. </p> <p>The parameter values are the same as for <code>reject</code>, but <code>\"autoreject_global\"</code> is not supported. <code>\"autoreject_local\"</code> here behaves differently, too: it is only used to exclude bad epochs from ICA fitting; we do not perform any interpolation.</p> Info <p>We don't support <code>\"autoreject_global\"</code> here (as opposed to <code>reject</code>) because in the past, we found that rejection thresholds were too strict before running ICA, i.e., too many epochs got rejected. <code>\"autoreject_local\"</code>, however, usually performed nicely. The <code>autoreject</code> documentation [recommends][https://autoreject.github.io/stable/auto_examples/plot_autoreject_workflow.html] running local <code>autoreject</code> before and after ICA, which can be achieved by setting both, <code>ica_reject</code> and <code>reject</code>, to <code>\"autoreject_local\"</code>.</p> <p>If passing a dictionary, the rejection limits will also be applied to the ECG and EOG epochs created to find heart beats and ocular artifacts.</p> Info <p>MNE-BIDS-Pipeline will automatically try to detect EOG and ECG artifacts in your data, and remove them. For this to work properly, it is recommended to not specify rejection thresholds for EOG and ECG channels here \u2013 otherwise, ICA won't be able to \"see\" these artifacts.</p> Info <p>This setting is applied only to the epochs that are used for fitting ICA. The goal is to make it easier for ICA to produce a good decomposition. After fitting, ICA is applied to the epochs to be analyzed, usually with one or more components removed (as to remove artifacts). But even after ICA cleaning, some epochs may still contain large-amplitude artifacts. Those epochs can then be rejected by using the <code>reject</code> parameter.</p> Example Python<pre><code>ica_reject = {'grad': 10e-10, 'mag': 20e-12, 'eeg': 400e-6}\nica_reject = {'grad': 15e-10}\nica_reject = None  # no rejection before fitting ICA\nica_reject = \"autoreject_global\"  # find global (per channel type) PTP thresholds before fitting ICA\nica_reject = \"autoreject_local\"  # find local (per channel) thresholds and repair epochs before fitting ICA\n</code></pre>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ica_algorithm","title":"ica_algorithm  <code>module-attribute</code>","text":"Python<pre><code>ica_algorithm = 'picard'\n</code></pre> <p>The ICA algorithm to use. <code>\"picard-extended_infomax\"</code> operates <code>picard</code> such that the generated ICA decomposition is identical to the one generated by the extended Infomax algorithm (but may converge in less time).</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ica_l_freq","title":"ica_l_freq  <code>module-attribute</code>","text":"Python<pre><code>ica_l_freq = 1.0\n</code></pre> <p>The cutoff frequency of the high-pass filter to apply before running ICA. Using a relatively high cutoff like 1 Hz will remove slow drifts from the data, yielding improved ICA results. Must be set to 1 Hz or above.</p> <p>Set to <code>None</code> to not apply an additional high-pass filter.</p> <p>Info</p> <p>The filter will be applied to raw data which was already filtered   according to the <code>l_freq</code> and <code>h_freq</code> settings. After filtering, the   data will be epoched, and the epochs will be submitted to ICA.</p> <p>Info</p> <p>The Pipeline will only allow you to perform ICA on data that has been high-pass filtered with a 1 Hz cutoff or higher. This is a conscious, opinionated (but partially data-driven) decision made by the developers. If you have reason to challenge this behavior, please get in touch with us so we can discuss.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ica_max_iterations","title":"ica_max_iterations  <code>module-attribute</code>","text":"Python<pre><code>ica_max_iterations = 500\n</code></pre> <p>Maximum number of iterations to decompose the data into independent components. A low number means to finish earlier, but the consequence is that the algorithm may not have finished converging. To ensure convergence, pick a high number here (e.g. 3000); yet the algorithm will terminate as soon as it determines that is has successfully converged, and not necessarily exhaust the maximum number of iterations. Note that the default of 200 seems to be sufficient for Picard in many datasets, because it converges quicker than the other algorithms; but e.g. for FastICA, this limit may be too low to achieve convergence.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ica_n_components","title":"ica_n_components  <code>module-attribute</code>","text":"Python<pre><code>ica_n_components = 0.8\n</code></pre> <p>MNE conducts ICA as a sort of a two-step procedure: First, a PCA is run on the data (trying to exclude zero-valued components in rank-deficient data); and in the second step, the principal components are passed to the actual ICA. You can select how many of the total principal components to pass to ICA \u2013\u00a0it can be all or just a subset. This determines how many independent components to fit, and can be controlled via this setting.</p> <p>If int, specifies the number of principal components that are passed to the ICA algorithm, which will be the number of independent components to fit. It must not be greater than the rank of your data (which is typically the number of channels, but may be less in some cases).</p> <p>If float between 0 and 1, all principal components with cumulative explained variance less than the value specified here will be passed to ICA.</p> <p>If <code>None</code>, all principal components will be used.</p> <p>This setting may drastically alter the time required to compute ICA.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ica_decim","title":"ica_decim  <code>module-attribute</code>","text":"Python<pre><code>ica_decim = None\n</code></pre> <p>The decimation parameter to compute ICA. If 5 it means that 1 every 5 sample is used by ICA solver. The higher the faster it is to run but the less data you have to compute a good ICA. Set to <code>1</code> or <code>None</code> to not perform any decimation.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ica_ctps_ecg_threshold","title":"ica_ctps_ecg_threshold  <code>module-attribute</code>","text":"Python<pre><code>ica_ctps_ecg_threshold = 0.1\n</code></pre> <p>The threshold parameter passed to <code>find_bads_ecg</code> method.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/ssp_ica.html#mne_bids_pipeline._config.ica_eog_threshold","title":"ica_eog_threshold  <code>module-attribute</code>","text":"Python<pre><code>ica_eog_threshold = 3.0\n</code></pre> <p>The threshold to use during automated EOG classification. Lower values mean that more ICs will be identified as EOG-related. If too low, the false-alarm rate increases dramatically.</p>","tags":["preprocessing","artifact-removal","raw","epochs","ssp","ica"]},{"location":"settings/preprocessing/stim_artifact.html","title":"Stimulation artifact","text":"<p>When using electric stimulation systems, e.g. for median nerve or index stimulation, it is frequent to have a stimulation artifact. This option allows to fix it by linear interpolation early in the pipeline on the raw data.</p>","tags":["preprocessing","artifact-removal","raw","epochs"]},{"location":"settings/preprocessing/stim_artifact.html#mne_bids_pipeline._config.fix_stim_artifact","title":"fix_stim_artifact  <code>module-attribute</code>","text":"Python<pre><code>fix_stim_artifact = False\n</code></pre> <p>Apply interpolation to fix stimulation artifact.</p> Example Python<pre><code>fix_stim_artifact = False\n</code></pre>","tags":["preprocessing","artifact-removal","raw","epochs"]},{"location":"settings/preprocessing/stim_artifact.html#mne_bids_pipeline._config.stim_artifact_tmin","title":"stim_artifact_tmin  <code>module-attribute</code>","text":"Python<pre><code>stim_artifact_tmin = 0.0\n</code></pre> <p>Start time of the interpolation window in seconds.</p> Example Python<pre><code>stim_artifact_tmin = 0.  # on stim onset\n</code></pre>","tags":["preprocessing","artifact-removal","raw","epochs"]},{"location":"settings/preprocessing/stim_artifact.html#mne_bids_pipeline._config.stim_artifact_tmax","title":"stim_artifact_tmax  <code>module-attribute</code>","text":"Python<pre><code>stim_artifact_tmax = 0.01\n</code></pre> <p>End time of the interpolation window in seconds.</p> Example Python<pre><code>stim_artifact_tmax = 0.01  # up to 10ms post-stimulation\n</code></pre>","tags":["preprocessing","artifact-removal","raw","epochs"]},{"location":"settings/reports/report_generation.html","title":"Report generation","text":"","tags":["report"]},{"location":"settings/reports/report_generation.html#mne_bids_pipeline._config.report_evoked_n_time_points","title":"report_evoked_n_time_points  <code>module-attribute</code>","text":"Python<pre><code>report_evoked_n_time_points = None\n</code></pre> <p>Specifies the number of time points to display for each evoked in the report. If <code>None</code>, it defaults to the current default in MNE-Python.</p> Example <p>Only display 5 time points per evoked Python<pre><code>report_evoked_n_time_points = 5\n</code></pre></p>","tags":["report"]},{"location":"settings/reports/report_generation.html#mne_bids_pipeline._config.report_stc_n_time_points","title":"report_stc_n_time_points  <code>module-attribute</code>","text":"Python<pre><code>report_stc_n_time_points = None\n</code></pre> <p>Specifies the number of time points to display for each source estimates in the report. If <code>None</code>, it defaults to the current default in MNE-Python.</p> Example <p>Only display 5 images per source estimate: Python<pre><code>report_stc_n_time_points = 5\n</code></pre></p>","tags":["report"]},{"location":"settings/sensor/contrasts.html","title":"Condition contrasts","text":"","tags":["epochs","evoked","contrast"]},{"location":"settings/sensor/contrasts.html#mne_bids_pipeline._config.contrasts","title":"contrasts  <code>module-attribute</code>","text":"Python<pre><code>contrasts = []\n</code></pre> <p>The conditions to contrast via a subtraction of ERPs / ERFs. The list elements can either be tuples or dictionaries (or a mix of both). Each element in the list corresponds to a single contrast.</p> <p>A tuple specifies a one-vs-one contrast, where the second condition is subtracted from the first.</p> <p>If a dictionary, must contain the following keys:</p> <ul> <li><code>name</code>: a custom name of the contrast</li> <li><code>conditions</code>: the conditions to contrast</li> <li><code>weights</code>: the weights associated with each condition.</li> </ul> <p>Pass an empty list to avoid calculation of any contrasts.</p> <p>For the contrasts to be computed, the appropriate conditions must have been epoched, and therefore the conditions should either match or be subsets of <code>conditions</code> above.</p> Example <p>Contrast the \"left\" and the \"right\" conditions by calculating <code>left - right</code> at every time point of the evoked responses: Python<pre><code>contrasts = [('left', 'right')]  # Note we pass a tuple inside the list!\n</code></pre></p> <p>Contrast the \"left\" and the \"right\" conditions within the \"auditory\" and the \"visual\" modality, and \"auditory\" vs \"visual\" regardless of side: Python<pre><code>contrasts = [('auditory/left', 'auditory/right'),\n             ('visual/left', 'visual/right'),\n             ('auditory', 'visual')]\n</code></pre></p> <p>Contrast the \"left\" and the \"right\" regardless of side, and compute an arbitrary contrast with a gradient of weights: Python<pre><code>contrasts = [\n    ('auditory/left', 'auditory/right'),\n    {\n        'name': 'gradedContrast',\n        'conditions': [\n            'auditory/left',\n            'auditory/right',\n            'visual/left',\n            'visual/right'\n        ],\n        'weights': [-1.5, -.5, .5, 1.5]\n    }\n]\n</code></pre></p>","tags":["epochs","evoked","contrast"]},{"location":"settings/sensor/group_level.html","title":"Group-level analysis","text":"","tags":["evoked","group-level"]},{"location":"settings/sensor/group_level.html#mne_bids_pipeline._config.interpolate_bads_grand_average","title":"interpolate_bads_grand_average  <code>module-attribute</code>","text":"Python<pre><code>interpolate_bads_grand_average = True\n</code></pre> <p>Interpolate bad sensors in each dataset before calculating the grand average. This parameter is passed to the <code>mne.grand_average</code> function via the keyword argument <code>interpolate_bads</code>. It requires to have channel locations set.</p> Example Python<pre><code>interpolate_bads_grand_average = True\n</code></pre>","tags":["evoked","group-level"]},{"location":"settings/sensor/mvpa.html","title":"Decoding / MVPA","text":"","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.decode","title":"decode  <code>module-attribute</code>","text":"Python<pre><code>decode = True\n</code></pre> <p>Whether to perform decoding (MVPA) on the specified <code>contrasts</code>. Classifiers will be trained on entire epochs (\"full-epochs decoding\"), and separately on each time point (\"time-by-time decoding\"), trying to learn how to distinguish the contrasting conditions.</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.decoding_which_epochs","title":"decoding_which_epochs  <code>module-attribute</code>","text":"Python<pre><code>decoding_which_epochs = 'cleaned'\n</code></pre> <p>This setting controls which epochs will be fed into the decoding algorithms.</p> <p>Info</p> <p>Decoding is a very powerful tool that often can deal with noisy data surprisingly well. Depending on the specific type of data, artifacts, and analysis performed, decoding performance may even improve with less pre-processed data, as processing steps such as ICA or SSP often remove parts of the signal, too, in addition to noise. By default, MNE-BIDS-Pipeline uses cleaned epochs for decoding, but you may choose to use entirely uncleaned epochs, or epochs before the final PTP-based rejection or Autoreject step.</p> <p>Info</p> <p>No other sensor- and source-level processing steps will be affected by this setting and use cleaned epochs only.</p> <p>If <code>\"uncleaned\"</code>, use the \"raw\" epochs before any ICA / SSP, PTP-based, or Autoreject cleaning (epochs with the filename <code>*_epo.fif</code>, without a <code>proc-</code> part).</p> <p>If <code>\"after_ica\"</code> or <code>\"after_ssp\"</code>, use the epochs that were cleaned via ICA or SSP, but before a followup cleaning through PTP-based rejection or Autorejct (epochs with the filename <code>*proc-ica_epo.fif</code> or <code>*proc-ssp_epo.fif</code>).</p> <p>If <code>\"cleaned\"</code>, use the epochs after ICA / SSP and the following cleaning through PTP-based rejection or Autoreject (epochs with the filename <code>*proc-clean_epo.fif</code>).</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.decoding_epochs_tmin","title":"decoding_epochs_tmin  <code>module-attribute</code>","text":"Python<pre><code>decoding_epochs_tmin = 0.0\n</code></pre> <p>The first time sample to use for full epochs decoding. By default it starts at 0. If <code>None</code>,, it starts at the beginning of the epoch. Does not affect time-by-time decoding.</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.decoding_epochs_tmax","title":"decoding_epochs_tmax  <code>module-attribute</code>","text":"Python<pre><code>decoding_epochs_tmax = None\n</code></pre> <p>The last time sample to use for full epochs decoding. By default it is set to None so it ends at the end of the epoch.</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.decoding_metric","title":"decoding_metric  <code>module-attribute</code>","text":"Python<pre><code>decoding_metric = 'roc_auc'\n</code></pre> <p>The metric to use for estimating classification performance. It can be <code>'roc_auc'</code> or <code>'accuracy'</code> \u2013 or any other metric supported by <code>scikit-learn</code>.</p> <p>With ROC AUC, chance level is the same regardless of class balance, that is, you don't need to be worried about exactly balancing class sizes.</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.decoding_n_splits","title":"decoding_n_splits  <code>module-attribute</code>","text":"Python<pre><code>decoding_n_splits = 5\n</code></pre> <p>The number of folds (also called \"splits\") to use in the K-fold cross-validation scheme.</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.decoding_time_generalization","title":"decoding_time_generalization  <code>module-attribute</code>","text":"Python<pre><code>decoding_time_generalization = False\n</code></pre> <p>Whether to perform time generalization.</p> <p>Time generalization (also called \"temporal generalization\" or \"generalization across time\", GAT) is an extension of the time-by-time decoding approach. Again, a separate classifier is trained on each time point. But instead of just testing the model on the same time point in the test data, it will be tested on all time points.</p> <p>[T]he manner in which the trained classifiers generalize across time, and from one experimental condition to another, sheds light on the temporal organization of information-processing stages.</p> <p>DOI: 10.1016/j.tics.2014.01.002</p> <p>Because each classifier is trained and tested on all time points, this procedure may take a significant amount of time.</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.decoding_time_generalization_decim","title":"decoding_time_generalization_decim  <code>module-attribute</code>","text":"Python<pre><code>decoding_time_generalization_decim = 1\n</code></pre> <p>Says how much to decimate data before time generalization decoding. This is done in addition to the decimation done at the epochs level via the <code>epochs_decim</code> parameter. This can be used to greatly speed up time generalization at the cost of lower time resolution in the resulting matrix.</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.decoding_csp","title":"decoding_csp  <code>module-attribute</code>","text":"Python<pre><code>decoding_csp = False\n</code></pre> <p>Whether to run decoding via Common Spatial Patterns (CSP) analysis on the data. CSP takes as input data covariances that are estimated on different time and frequency ranges. This allows to obtain decoding scores defined over time and frequency.</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.decoding_csp_times","title":"decoding_csp_times  <code>module-attribute</code>","text":"Python<pre><code>decoding_csp_times = None\n</code></pre> <p>The edges of the time bins to use for CSP decoding. Must contain at least two elements. By default, 5 equally-spaced bins are created across the non-negative time range of the epochs. All specified time points must be contained in the epochs interval. If <code>None</code>, do not perform time-frequency analysis, and only run CSP on frequency data.</p> Example <p>Create 3 equidistant time bins (0\u20130.2, 0.2\u20130.4, 0.4\u20130.6 sec): Python<pre><code>decoding_csp_times = np.linspace(start=0, stop=0.6, num=4)\n</code></pre> Create 2 time bins of different durations (0\u20130.4, 0.4\u20130.6 sec): Python<pre><code>decoding_csp_times = [0, 0.4, 0.6]\n</code></pre></p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.decoding_csp_freqs","title":"decoding_csp_freqs  <code>module-attribute</code>","text":"Python<pre><code>decoding_csp_freqs = None\n</code></pre> <p>The edges of the frequency bins to use for CSP decoding.</p> <p>This parameter must be a dictionary with: - keys specifying the unique identifier or \"name\" to use for the frequency   range to be treated jointly during statistical testing (such as \"alpha\" or   \"beta\"), and - values must be list-like objects containing at least two scalar values,   specifying the edges of the respective frequency bin(s), e.g., <code>[8, 12]</code>.</p> <p>Defaults to two frequency bins, one from <code>time_frequency_freq_min</code> to the midpoint between this value and <code>time_frequency_freq_max</code>; and the other from that midpoint to <code>time_frequency_freq_max</code>.</p> Example <p>Create two frequency bins, one for 4\u20138 Hz, and another for 8\u201314 Hz, which will be clustered together during statistical testing (in the time-frequency plane): Python<pre><code>decoding_csp_freqs = {\n    'custom_range': [4, 8, 14]\n}\n</code></pre> Create the same two frequency bins, but treat them separately during statistical testing (i.e., temporal clustering only): Python<pre><code>decoding_csp_freqs = {\n    'theta': [4, 8],\n    'alpha': [8, 14]\n}\n</code></pre> Create 5 equidistant frequency bins from 4 to 14 Hz: ```python decoding_csp_freqs = {     'custom_range': np.linspace(         start=4,         stop=14,         num=5+1  # We need one more to account for the endpoint!     ) }</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.n_boot","title":"n_boot  <code>module-attribute</code>","text":"Python<pre><code>n_boot = 5000\n</code></pre> <p>The number of bootstrap resamples when estimating the standard error and confidence interval of the mean decoding scores.</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.cluster_forming_t_threshold","title":"cluster_forming_t_threshold  <code>module-attribute</code>","text":"Python<pre><code>cluster_forming_t_threshold = None\n</code></pre> <p>The t-value threshold to use for forming clusters in the cluster-based permutation test run on the the time-by-time decoding scores. Data points with absolute t-values greater than this value will be used to form clusters. If <code>None</code>, the threshold will be automatically determined to correspond to a p-value of 0.05 for the given number of participants in a one-tailed test.</p> <p>Info</p> <p>Only points with the same sign will be clustered together.</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.cluster_n_permutations","title":"cluster_n_permutations  <code>module-attribute</code>","text":"Python<pre><code>cluster_n_permutations = 10000\n</code></pre> <p>The maximum number of permutations to perform in a cluster-based permutation test to determine the significance of the decoding scores across participants.</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/mvpa.html#mne_bids_pipeline._config.cluster_permutation_p_threshold","title":"cluster_permutation_p_threshold  <code>module-attribute</code>","text":"Python<pre><code>cluster_permutation_p_threshold = 0.05\n</code></pre> <p>The alpha level (p-value, p threshold) to use for rejecting the null hypothesis that the clusters show no significant difference between conditions. This is used in the permutation test which takes place after forming the clusters.</p> <p>Info</p> <p>To control how clusters are formed, see <code>cluster_forming_t_threshold</code>.</p>","tags":["epochs","evoked","contrast","decoding","mvpa"]},{"location":"settings/sensor/time_freq.html","title":"Time-frequency analysis","text":"","tags":["epochs","evoked","time-frequency"]},{"location":"settings/sensor/time_freq.html#mne_bids_pipeline._config.time_frequency_conditions","title":"time_frequency_conditions  <code>module-attribute</code>","text":"Python<pre><code>time_frequency_conditions = []\n</code></pre> <p>The conditions to compute time-frequency decomposition on.</p> Example Python<pre><code>time_frequency_conditions = ['left', 'right']\n</code></pre>","tags":["epochs","evoked","time-frequency"]},{"location":"settings/sensor/time_freq.html#mne_bids_pipeline._config.time_frequency_freq_min","title":"time_frequency_freq_min  <code>module-attribute</code>","text":"Python<pre><code>time_frequency_freq_min = 8\n</code></pre> <p>Minimum frequency for the time frequency analysis, in Hz.</p> Example Python<pre><code>time_frequency_freq_min = 0.3  # 0.3 Hz\n</code></pre>","tags":["epochs","evoked","time-frequency"]},{"location":"settings/sensor/time_freq.html#mne_bids_pipeline._config.time_frequency_freq_max","title":"time_frequency_freq_max  <code>module-attribute</code>","text":"Python<pre><code>time_frequency_freq_max = 40\n</code></pre> <p>Maximum frequency for the time frequency analysis, in Hz.</p> Example Python<pre><code>time_frequency_freq_max = 22.3  # 22.3 Hz\n</code></pre>","tags":["epochs","evoked","time-frequency"]},{"location":"settings/sensor/time_freq.html#mne_bids_pipeline._config.time_frequency_cycles","title":"time_frequency_cycles  <code>module-attribute</code>","text":"Python<pre><code>time_frequency_cycles = None\n</code></pre> <p>The number of cycles to use in the Morlet wavelet. This can be a single number or one per frequency, where frequencies are calculated via <code>np.arange(time_frequency_freq_min, time_frequency_freq_max)</code>. If <code>None</code>, uses <code>np.arange(time_frequency_freq_min, time_frequency_freq_max) / 3</code>.</p>","tags":["epochs","evoked","time-frequency"]},{"location":"settings/sensor/time_freq.html#mne_bids_pipeline._config.time_frequency_subtract_evoked","title":"time_frequency_subtract_evoked  <code>module-attribute</code>","text":"Python<pre><code>time_frequency_subtract_evoked = False\n</code></pre> <p>Whether to subtract the evoked response (averaged across all epochs) from the epochs before passing them to time-frequency analysis. Set this to <code>True</code> to highlight induced activity.</p> <p>Info</p> <p>This also applies to CSP analysis.</p>","tags":["epochs","evoked","time-frequency"]},{"location":"settings/sensor/time_freq.html#mne_bids_pipeline._config.time_frequency_baseline","title":"time_frequency_baseline  <code>module-attribute</code>","text":"Python<pre><code>time_frequency_baseline = None\n</code></pre> <p>Baseline period to use for the time-frequency analysis. If <code>None</code>, no baseline.</p> Example Python<pre><code>time_frequency_baseline = (None, 0)\n</code></pre>","tags":["epochs","evoked","time-frequency"]},{"location":"settings/sensor/time_freq.html#mne_bids_pipeline._config.time_frequency_baseline_mode","title":"time_frequency_baseline_mode  <code>module-attribute</code>","text":"Python<pre><code>time_frequency_baseline_mode = 'mean'\n</code></pre> <p>Baseline mode to use for the time-frequency analysis. Can be chosen among: \"mean\" or \"ratio\" or \"logratio\" or \"percent\" or \"zscore\" or \"zlogratio\".</p> Example Python<pre><code>time_frequency_baseline_mode = 'mean'\n</code></pre>","tags":["epochs","evoked","time-frequency"]},{"location":"settings/sensor/time_freq.html#mne_bids_pipeline._config.time_frequency_crop","title":"time_frequency_crop  <code>module-attribute</code>","text":"Python<pre><code>time_frequency_crop = None\n</code></pre> <p>Period and frequency range to crop the time-frequency analysis to. If <code>None</code>, no cropping.</p> Example Python<pre><code>time_frequency_crop = dict(tmin=-0.3, tmax=0.5, fmin=5, fmax=20)\n</code></pre>","tags":["epochs","evoked","time-frequency"]},{"location":"settings/source/bem.html","title":"BEM surface","text":"","tags":["inverse-solution","bem","freesurfer"]},{"location":"settings/source/bem.html#mne_bids_pipeline._config.use_template_mri","title":"use_template_mri  <code>module-attribute</code>","text":"Python<pre><code>use_template_mri = None\n</code></pre> <p>Whether to use a template MRI subject such as FreeSurfer's <code>fsaverage</code> subject. This may come in handy if you don't have individual MR scans of your participants, as is often the case in EEG studies.</p> <p>Note that the template MRI subject must be available as a subject in your subjects_dir. You can use for example a scaled version of fsaverage that could get with <code>mne.scale_mri</code>. Scaling fsaverage can be a solution to problems that occur when the head of a subject is small compared to <code>fsaverage</code> and, therefore, the default coregistration mislocalizes MEG sensors inside the head.</p> Example Python<pre><code>use_template_mri = \"fsaverage\"\n</code></pre>","tags":["inverse-solution","bem","freesurfer"]},{"location":"settings/source/bem.html#mne_bids_pipeline._config.adjust_coreg","title":"adjust_coreg  <code>module-attribute</code>","text":"Python<pre><code>adjust_coreg = False\n</code></pre> <p>Whether to adjust the coregistration between the MRI and the channels locations, possibly combined with the digitized head shape points. Setting it to True is mandatory if you use a template MRI subject that is different from <code>fsaverage</code>.</p> Example Python<pre><code>adjust_coreg = True\n</code></pre>","tags":["inverse-solution","bem","freesurfer"]},{"location":"settings/source/bem.html#mne_bids_pipeline._config.bem_mri_images","title":"bem_mri_images  <code>module-attribute</code>","text":"Python<pre><code>bem_mri_images = 'auto'\n</code></pre> <p>Which types of MRI images to use when creating the BEM model. If <code>'FLASH'</code>, use FLASH MRI images, and raise an exception if they cannot be found.</p> Advice <p>It is recommended to use the FLASH images if available, as the quality of the extracted BEM surfaces will be higher.</p> <p>If <code>'T1'</code>, create the BEM surfaces from the T1-weighted images using the <code>watershed</code> algorithm.</p> <p>If <code>'auto'</code>, use FLASH images if available, and use the `watershed`` algorithm with the T1-weighted images otherwise.</p>","tags":["inverse-solution","bem","freesurfer"]},{"location":"settings/source/bem.html#mne_bids_pipeline._config.recreate_bem","title":"recreate_bem  <code>module-attribute</code>","text":"Python<pre><code>recreate_bem = False\n</code></pre> <p>Whether to re-create the BEM surfaces, even if existing surfaces have been found. If <code>False</code>, the BEM surfaces are only created if they do not exist already. <code>True</code> forces their recreation, overwriting existing BEM surfaces.</p>","tags":["inverse-solution","bem","freesurfer"]},{"location":"settings/source/bem.html#mne_bids_pipeline._config.recreate_scalp_surface","title":"recreate_scalp_surface  <code>module-attribute</code>","text":"Python<pre><code>recreate_scalp_surface = False\n</code></pre> <p>Whether to re-create the scalp surfaces used for visualization of the coregistration in the report and the lower-density coregistration surfaces. If <code>False</code>, the scalp surface is only created if it does not exist already. If <code>True</code>, forces a re-computation.</p>","tags":["inverse-solution","bem","freesurfer"]},{"location":"settings/source/bem.html#mne_bids_pipeline._config.freesurfer_verbose","title":"freesurfer_verbose  <code>module-attribute</code>","text":"Python<pre><code>freesurfer_verbose = False\n</code></pre> <p>Whether to print the complete output of FreeSurfer commands. Note that if <code>False</code>, no FreeSurfer output might be displayed at all!</p>","tags":["inverse-solution","bem","freesurfer"]},{"location":"settings/source/forward.html","title":"Source space & forward solution","text":"","tags":["inverse-solution","forward-model"]},{"location":"settings/source/forward.html#mne_bids_pipeline._config.mri_t1_path_generator","title":"mri_t1_path_generator  <code>module-attribute</code>","text":"Python<pre><code>mri_t1_path_generator = None\n</code></pre> <p>To perform source-level analyses, the Pipeline needs to generate a transformation matrix that translates coordinates from MEG and EEG sensor space to MRI space, and vice versa. This process, called \"coregistration\", requires access to both, the electrophyisiological recordings as well as T1-weighted MRI images of the same participant. If both are stored within the same session, the Pipeline (or, more specifically, MNE-BIDS) can find the respective files automatically.</p> <p>However, in certain situations, this is not possible. Examples include:</p> <ul> <li>MRI was conducted during a different session than the electrophysiological   recording.</li> <li>MRI was conducted in a single session, while electrophysiological recordings   spanned across several sessions.</li> <li>MRI and electrophysiological data are stored in separate BIDS datasets to   allow easier storage and distribution in certain situations.</li> </ul> <p>To allow the Pipeline to find the correct MRI images and perform coregistration automatically, we provide a \"hook\" that allows you to provide a custom function whose output tells the Pipeline where to find the T1-weighted image.</p> <p>The function is expected to accept a single parameter: The Pipeline will pass a <code>BIDSPath</code> with the following parameters set based on the currently processed electrophysiological data:</p> <ul> <li>the subject ID, <code>BIDSPath.subject</code></li> <li>the experimental session, <code>BIDSPath.session</code></li> <li>the BIDS root, <code>BIDSPath.root</code></li> </ul> <p>This <code>BIDSPath</code> can then be modified \u2013 or an entirely new <code>BIDSPath</code> can be generated \u2013 and returned by the function, pointing to the T1-weighted image.</p> <p>Info</p> <p>The function accepts and returns a single <code>BIDSPath</code>.</p> Example <p>The MRI session is different than the electrophysiological session: Python<pre><code>def get_t1_from_meeg(bids_path):\n    bids_path.session = 'MRI'\n    return bids_path\n\n\nmri_t1_path_generator = get_t1_from_meeg\n</code></pre></p> <p>The MRI recording is stored in a different BIDS dataset than the electrophysiological data: Python<pre><code>def get_t1_from_meeg(bids_path):\n    bids_path.root = '/data/mri'\n    return bids_path\n\n\nmri_t1_path_generator = get_t1_from_meeg\n</code></pre></p>","tags":["inverse-solution","forward-model"]},{"location":"settings/source/forward.html#mne_bids_pipeline._config.mri_landmarks_kind","title":"mri_landmarks_kind  <code>module-attribute</code>","text":"Python<pre><code>mri_landmarks_kind = None\n</code></pre> <p>This config option allows to look for specific landmarks in the json sidecar file of the T1 MRI file. This can be useful when we have different fiducials coordinates e.g. the manually positioned fiducials or the fiducials derived for the coregistration transformation of a given session.</p> Example <p>We have one MRI session and we have landmarks with a kind indicating how to find the landmarks for each session:</p> Python<pre><code>def mri_landmarks_kind(bids_path):\n    return f\"ses-{bids_path.session}\"\n</code></pre>","tags":["inverse-solution","forward-model"]},{"location":"settings/source/forward.html#mne_bids_pipeline._config.spacing","title":"spacing  <code>module-attribute</code>","text":"Python<pre><code>spacing = 'oct6'\n</code></pre> <p>The spacing to use. Can be <code>'ico#'</code> for a recursively subdivided icosahedron, <code>'oct#'</code> for a recursively subdivided octahedron, <code>'all'</code> for all points, or an integer to use approximate distance-based spacing (in mm). See (the respective MNE-Python documentation) [https://mne.tools/dev/overview/cookbook.html#setting-up-the-source-space] for more info.</p>","tags":["inverse-solution","forward-model"]},{"location":"settings/source/forward.html#mne_bids_pipeline._config.mindist","title":"mindist  <code>module-attribute</code>","text":"Python<pre><code>mindist = 5\n</code></pre> <p>Exclude points closer than this distance (mm) to the bounding surface.</p>","tags":["inverse-solution","forward-model"]},{"location":"settings/source/forward.html#mne_bids_pipeline._config.source_info_path_update","title":"source_info_path_update  <code>module-attribute</code>","text":"Python<pre><code>source_info_path_update = dict(suffix='ave')\n</code></pre> <p>When computing the forward and inverse solutions, by default the pipeline retrieves the <code>mne.Info</code> object from the cleaned evoked data. However, in certain situations you may wish to use a different <code>Info</code>.</p> <p>This parameter allows you to explicitly specify from which file to retrieve the <code>mne.Info</code> object. Use this parameter to supply a dictionary to <code>BIDSPath.update()</code> during the forward and inverse processing steps.</p> Example <p>Use the <code>Info</code> object stored in the cleaned epochs: Python<pre><code>source_info_path_update = {'processing': 'clean',\n                           'suffix': 'epo'}\n</code></pre></p>","tags":["inverse-solution","forward-model"]},{"location":"settings/source/general.html","title":"General settings","text":"","tags":["inverse-solution"]},{"location":"settings/source/general.html#mne_bids_pipeline._config.run_source_estimation","title":"run_source_estimation  <code>module-attribute</code>","text":"Python<pre><code>run_source_estimation = True\n</code></pre> <p>Whether to run source estimation processing steps if not explicitly requested.</p>","tags":["inverse-solution"]},{"location":"settings/source/inverse.html","title":"Inverse solution","text":"","tags":["inverse-solution"]},{"location":"settings/source/inverse.html#mne_bids_pipeline._config.loose","title":"loose  <code>module-attribute</code>","text":"Python<pre><code>loose = 0.2\n</code></pre> <p>Value that weights the source variances of the dipole components that are parallel (tangential) to the cortical surface. If <code>0</code>, then the inverse solution is computed with fixed orientation. If <code>1</code>, it corresponds to free orientation. The default value, <code>'auto'</code>, is set to <code>0.2</code> for surface-oriented source spaces, and to <code>1.0</code> for volumetric, discrete, or mixed source spaces, unless <code>fixed is True</code> in which case the value 0. is used.</p>","tags":["inverse-solution"]},{"location":"settings/source/inverse.html#mne_bids_pipeline._config.depth","title":"depth  <code>module-attribute</code>","text":"Python<pre><code>depth = 0.8\n</code></pre> <p>If float (default 0.8), it acts as the depth weighting exponent (<code>exp</code>) to use (must be between 0 and 1). None is equivalent to 0, meaning no depth weighting is performed. Can also be a <code>dict</code> containing additional keyword arguments to pass to :func:<code>mne.forward.compute_depth_prior</code> (see docstring for details and defaults).</p>","tags":["inverse-solution"]},{"location":"settings/source/inverse.html#mne_bids_pipeline._config.inverse_method","title":"inverse_method  <code>module-attribute</code>","text":"Python<pre><code>inverse_method = 'dSPM'\n</code></pre> <p>Use minimum norm, dSPM (default), sLORETA, or eLORETA to calculate the inverse solution.</p>","tags":["inverse-solution"]},{"location":"settings/source/inverse.html#mne_bids_pipeline._config.noise_cov","title":"noise_cov  <code>module-attribute</code>","text":"Python<pre><code>noise_cov = (None, 0)\n</code></pre> <p>Specify how to estimate the noise covariance matrix, which is used in inverse modeling.</p> <p>If a tuple, it takes the form <code>(tmin, tmax)</code> with the time specified in seconds. If the first value of the tuple is <code>None</code>, the considered period starts at the beginning of the epoch. If the second value of the tuple is <code>None</code>, the considered period ends at the end of the epoch. The default, <code>(None, 0)</code>, includes the entire period before the event, which is typically the pre-stimulus period.</p> <p>If <code>'emptyroom'</code>, the noise covariance matrix will be estimated from an empty-room MEG recording. The empty-room recording will be automatically selected based on recording date and time. This cannot be used with EEG data.</p> <p>If <code>'rest'</code>, the noise covariance will be estimated from a resting-state recording (i.e., a recording with <code>task-rest</code> and without a <code>run</code> in the filename).</p> <p>If <code>'ad-hoc'</code>, a diagonal ad-hoc noise covariance matrix will be used.</p> <p>You can also pass a function that accepts a <code>BIDSPath</code> and returns an <code>mne.Covariance</code> instance. The <code>BIDSPath</code> will point to the file containing the generated evoked data.</p> Example <p>Use the period from start of the epoch until 100 ms before the experimental event: Python<pre><code>noise_cov = (None, -0.1)\n</code></pre></p> <p>Use the time period from the experimental event until the end of the epoch: Python<pre><code>noise_cov = (0, None)\n</code></pre></p> <p>Use an empty-room recording: Python<pre><code>noise_cov = 'emptyroom'\n</code></pre></p> <p>Use a resting-state recording: Python<pre><code>noise_cov = 'rest'\n</code></pre></p> <p>Use an ad-hoc covariance: Python<pre><code>noise_cov = 'ad-hoc'\n</code></pre></p> <p>Use a custom covariance derived from raw data: Python<pre><code>def noise_cov(bids_path):\n    bp = bids_path.copy().update(task='rest', run=None, suffix='meg')\n    raw_rest = mne_bids.read_raw_bids(bp)\n    raw.crop(tmin=5, tmax=60)\n    cov = mne.compute_raw_covariance(raw, rank='info')\n    return cov\n</code></pre></p>","tags":["inverse-solution"]},{"location":"settings/source/inverse.html#mne_bids_pipeline._config.source_info_path_update","title":"source_info_path_update  <code>module-attribute</code>","text":"Python<pre><code>source_info_path_update = dict(suffix='ave')\n</code></pre> <p>When computing the forward and inverse solutions, by default the pipeline retrieves the <code>mne.Info</code> object from the cleaned evoked data. However, in certain situations you may wish to use a different <code>Info</code>.</p> <p>This parameter allows you to explicitly specify from which file to retrieve the <code>mne.Info</code> object. Use this parameter to supply a dictionary to <code>BIDSPath.update()</code> during the forward and inverse processing steps.</p> Example <p>Use the <code>Info</code> object stored in the cleaned epochs: Python<pre><code>source_info_path_update = {'processing': 'clean',\n                           'suffix': 'epo'}\n</code></pre></p>","tags":["inverse-solution"]},{"location":"settings/source/inverse.html#mne_bids_pipeline._config.inverse_targets","title":"inverse_targets  <code>module-attribute</code>","text":"Python<pre><code>inverse_targets = ['evoked']\n</code></pre> <p>On which data to apply the inverse operator. Currently, the only supported target is <code>'evoked'</code>. If no inverse computation should be done, pass an empty list, <code>[]</code>.</p> Example <p>Compute the inverse solution on evoked data: Python<pre><code>inverse_targets = ['evoked']\n</code></pre></p> <p>Don't compute an inverse solution: Python<pre><code>inverse_targets = []\n</code></pre></p>","tags":["inverse-solution"]},{"location":"tags.html","title":"Tags","text":""},{"location":"tags.html#artifact-removal","title":"artifact-removal","text":"<ul> <li>Amplitude-based artifact rejection</li> <li>Break detection</li> <li>SSP &amp; ICA</li> <li>Stimulation artifact</li> </ul>"},{"location":"tags.html#bad-channels","title":"bad-channels","text":"<ul> <li>Bad channel detection</li> </ul>"},{"location":"tags.html#bem","title":"bem","text":"<ul> <li>BEM surface</li> </ul>"},{"location":"tags.html#contrast","title":"contrast","text":"<ul> <li>Condition contrasts</li> <li>Decoding / MVPA</li> </ul>"},{"location":"tags.html#decimation","title":"decimation","text":"<ul> <li>Resampling</li> </ul>"},{"location":"tags.html#decoding","title":"decoding","text":"<ul> <li>Decoding / MVPA</li> </ul>"},{"location":"tags.html#epochs","title":"epochs","text":"<ul> <li>Amplitude-based artifact rejection</li> <li>Epoching</li> <li>Resampling</li> <li>SSP &amp; ICA</li> <li>Stimulation artifact</li> <li>Condition contrasts</li> <li>Decoding / MVPA</li> <li>Time-frequency analysis</li> </ul>"},{"location":"tags.html#events","title":"events","text":"<ul> <li>Break detection</li> <li>Epoching</li> </ul>"},{"location":"tags.html#evoked","title":"evoked","text":"<ul> <li>Condition contrasts</li> <li>Group-level analysis</li> <li>Decoding / MVPA</li> <li>Time-frequency analysis</li> </ul>"},{"location":"tags.html#forward-model","title":"forward-model","text":"<ul> <li>Source space &amp; forward solution</li> </ul>"},{"location":"tags.html#freesurfer","title":"freesurfer","text":"<ul> <li>BEM surface</li> </ul>"},{"location":"tags.html#frequency-filter","title":"frequency-filter","text":"<ul> <li>Filtering</li> </ul>"},{"location":"tags.html#group-level","title":"group-level","text":"<ul> <li>Group-level analysis</li> </ul>"},{"location":"tags.html#ica","title":"ica","text":"<ul> <li>SSP &amp; ICA</li> </ul>"},{"location":"tags.html#inverse-solution","title":"inverse-solution","text":"<ul> <li>BEM surface</li> <li>Source space &amp; forward solution</li> <li>General settings</li> <li>Inverse solution</li> </ul>"},{"location":"tags.html#maxwell-filter","title":"maxwell-filter","text":"<ul> <li>Maxwell filter</li> </ul>"},{"location":"tags.html#metadata","title":"metadata","text":"<ul> <li>Epoching</li> </ul>"},{"location":"tags.html#mvpa","title":"mvpa","text":"<ul> <li>Decoding / MVPA</li> </ul>"},{"location":"tags.html#preprocessing","title":"preprocessing","text":"<ul> <li>Amplitude-based artifact rejection</li> <li>Bad channel detection</li> <li>Break detection</li> <li>Epoching</li> <li>Filtering</li> <li>Maxwell filter</li> <li>Resampling</li> <li>SSP &amp; ICA</li> <li>Stimulation artifact</li> </ul>"},{"location":"tags.html#raw","title":"raw","text":"<ul> <li>Bad channel detection</li> <li>Break detection</li> <li>Filtering</li> <li>Maxwell filter</li> <li>Resampling</li> <li>SSP &amp; ICA</li> <li>Stimulation artifact</li> </ul>"},{"location":"tags.html#report","title":"report","text":"<ul> <li>Report generation</li> </ul>"},{"location":"tags.html#resampling","title":"resampling","text":"<ul> <li>Resampling</li> </ul>"},{"location":"tags.html#resting-state","title":"resting-state","text":"<ul> <li>Epoching</li> </ul>"},{"location":"tags.html#ssp","title":"ssp","text":"<ul> <li>SSP &amp; ICA</li> </ul>"},{"location":"tags.html#time-frequency","title":"time-frequency","text":"<ul> <li>Time-frequency analysis</li> </ul>"}]}